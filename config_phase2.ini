[Model]

# 初始树数量（控制模型基础拟合能力，欠拟合可增大）
n_estimators = 30
# 增量训练每次增加的树数量（增量更新强度，不足可增大）
increment_estimators = 10
; LightGBM核心参数（影响模型拟合能力，重点调优项）
; 单棵树的最大叶子数（叶子节点数，欠拟合增大，过拟合减小）
num_leaves = 16
; 学习率（步长，过小收敛慢，过大易震荡，建议0.01-0.1）
learning_rate = 0.02
; L1正则化（抑制过拟合，值越大惩罚越强）
reg_alpha = 2.5
; L2正则化（抑制过拟合，值越大惩罚越强）
reg_lambda = 8.0
; 每个叶子最小样本数（强烈建议：抑制记忆噪声/过拟合）
min_data_in_leaf = 50
; 样本采样比例（bagging）
bagging_fraction = 0.9
; 每隔多少轮进行一次bagging（>0时才生效）
# ========= 增量训练窗口参数（少量样本 / Phase2） =========
# Phase2 阶段限制更严格，防止“小样本 + 大窗口”过拟合
incremental_window_limit = 3000
# 兜底：如果不想用 schedule，也至少保留这个
incremental_lookback_days = 10

[ModelEval]
# 评估样本数量（从数据库读取最新 eval_size 条）,根据实际情况的样本数量级调整
eval_size = 150
# 评估集切分策略：latest | time_holdout
eval_split_mode = latest
# time_holdout 最少评估样本数，不足则自动回退为 latest
min_holdout_samples = 20

