"""
ç…¤çŸ¿ç“¦æ–¯é£é™©é¢„æµ‹ç³»ç»Ÿ - ä¸»æ¨¡å‹ç±»
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„æ¨¡å‹æ¥å£
"""
import os
from datetime import datetime

import numpy as np
import pandas as pd
from filelock import FileLock
from loguru import logger
import configparser

# å¯¼å…¥å„åŠŸèƒ½æ¨¡å—
from config_utils import ConfigUtils
from fault_calculator import FaultCalculator
from regional_measure_calculator import RegionalMeasureCalculator
from data_preprocessor import DataPreprocessor
from model_trainer import ModelTrainer
from model_evaluator import ModelEvaluator
from model_predictor import ModelPredictor
from model_manager import ModelManager
from db_utils import DBUtils


class CoalMineRiskModel:
    """
    ç…¤çŸ¿ç“¦æ–¯é£é™©é¢„æµ‹æ¨¡å‹ï¼ˆLightGBMå¤šç›®æ ‡å›å½’ï¼‰
    ä½¿ç”¨ç»„åˆæ¨¡å¼è€Œéç»§æ‰¿æ¥æ•´åˆå„åŠŸèƒ½æ¨¡å—
    """

    def __init__(self, config_path="config.ini",
                 fault_calculator=None,
                 regional_calculator=None,
                 data_preprocessor=None,
                 model_trainer=None,
                 model_evaluator=None,
                 model_predictor=None,
                 model_manager=None,
                 db_utils=None):
        """
        æ¨¡å‹åˆå§‹åŒ–å…¥å£ï¼šè¯»å–é…ç½®â†’åˆå§‹åŒ–ç›®å½•â†’åŠ è½½å‚æ•°â†’åˆå§‹åŒ–ä¾èµ–â†’åŠ è½½å·²æœ‰æ¨¡å‹
        """
        # Step 1: åˆå§‹åŒ–é…ç½®
        self.config_path = config_path
        self.config = configparser.ConfigParser()
        self.config.read(config_path, encoding="utf-8")
        logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶ï¼š{config_path}")

        # Step 2: åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å—
        self.config_utils = ConfigUtils(config_path)
        self.fault_calculator = fault_calculator or FaultCalculator(config_path)
        self.regional_calculator = regional_calculator or RegionalMeasureCalculator(config_path)
        self.data_preprocessor = data_preprocessor or DataPreprocessor(config_path)
        self.model_trainer = model_trainer or ModelTrainer(self.config)
        self.model_trainer.config_filename = os.path.basename(config_path)
        self.model_evaluator = model_evaluator or ModelEvaluator(config_path)
        self.model_predictor = model_predictor or ModelPredictor()

        # Step 3: åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        self.model_dir = self.config_utils._get_config_value("Model", "model_dir", "models")
        self.model_manager = model_manager or ModelManager(self.model_dir)

        # Step 4: åŠ è½½è®­ç»ƒæ ¸å¿ƒå‚æ•°
        self.full_train_threshold = self.config_utils._get_config_value("Model", "full_train_threshold", 6, is_int=True)
        self.min_train_samples = self.config_utils._get_config_value("Model", "min_train_samples", 6, is_int=True)

        # Step 5: æ¨¡å‹æ ¸å¿ƒçŠ¶æ€åˆå§‹åŒ–
        self.models = {}
        self.preprocessor = None
        self.training_features = None
        self.is_trained = False
        # ç®—æ³•é”å®šï¼šä¸€æ—¦å­˜åœ¨å·²è®­ç»ƒæ¨¡å‹ï¼ˆalgorithm.pklï¼‰ï¼Œç³»ç»Ÿè¿è¡Œä¸­å°†å¿½ç•¥é…ç½®æ–‡ä»¶é‡Œçš„algorithmå˜æ›´
        self.locked_algorithm = None
        self.total_samples = 0
        self.eval_history = []
        self.training_stats = []
        self.baseline_rmse = None
        self._fitted_feature_order = None

        # æ³¨æ„ï¼šä¸å†åŒ…å«ç“¦æ–¯æ¶Œå‡ºé‡ç›¸å…³çŠ¶æ€
        self.note = "æ¨¡å‹å·²é‡æ„ï¼Œç“¦æ–¯æ¶Œå‡ºé‡è¯·ä½¿ç”¨ç‹¬ç«‹çš„/calculate_gas_emission_sourceæ¥å£è®¡ç®—"
        # Step 6: åˆå§‹åŒ–æ•°æ®åº“å·¥å…·ä¸è·¨è¿›ç¨‹é”
        self.db = DBUtils(config_path=config_path)
        self.file_lock = FileLock(self.model_manager.lock_file_path)
        logger.info(f"è·¨è¿›ç¨‹é”åˆå§‹åŒ–å®Œæˆï¼Œé”æ–‡ä»¶è·¯å¾„ï¼š{self.model_manager.lock_file_path}")
        # Step 7: åŠ è½½å·²æœ‰æ¨¡å‹ä¸åŒæ­¥æ•°æ®åº“æ ·æœ¬æ•°
        self._load_model()
        # Step 7.1: ç®—æ³•é”å®šï¼ˆè‹¥å·²æœ‰æ¨¡å‹ï¼Œåç»­reload_config/retrainä¸å¾—åˆ‡æ¢ç®—æ³•ï¼‰
        locked = self.model_manager.get_locked_algorithm()
        if locked:
            self.locked_algorithm = locked
            # è¦†ç›–trainerç®—æ³•ï¼ˆå³ä½¿é…ç½®æ–‡ä»¶è¢«ä¿®æ”¹ï¼‰
            if getattr(self.model_trainer, "algorithm", None) != locked:
                logger.warning(
                    f"æ£€æµ‹åˆ°å·²è®­ç»ƒæ¨¡å‹ç®—æ³•é”å®šä¸º {locked}ï¼Œå°†è¦†ç›–å½“å‰é…ç½®/Trainerç®—æ³•ï¼ˆå¯åŠ¨åä¸å¯åˆ‡æ¢ï¼‰"
                )
            self.model_trainer.algorithm = locked
        else:
            # å°šæœªè®­ç»ƒè¿‡æ¨¡å‹ï¼šä»¥å½“å‰é…ç½®ä¸ºå‡†ï¼Œä½†è®°å½•ä¸ºâ€œé¢„æœŸé”å®šç®—æ³•â€
            self.locked_algorithm = getattr(self.model_trainer, "algorithm", None)

        try:
            self.total_samples = self.model_manager.get_total_samples_from_db(self.db)
        except Exception as e:
            self.total_samples = 0
            logger.warning(f"åŒæ­¥æ•°æ®åº“æ ·æœ¬æ•°å¤±è´¥ï¼š{str(e)}ï¼Œåˆå§‹åŒ–ä¸º0")

        # Step 8: æ§åˆ¶å°è¾“å‡ºåˆå§‹åŒ–ç»“æœ
        self._print_header("æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        self.current_config = config_path  # è®°å½•å½“å‰ä½¿ç”¨çš„é…ç½®æ–‡ä»¶
        logger.info(f"å½“å‰é…ç½®æ–‡ä»¶ï¼š{self.current_config}")
        # æ·»åŠ ç¼ºå¤±çš„å±æ€§åˆå§‹åŒ–
        self.fixed_evaluation_set = None  # å›ºå®šè¯„ä¼°æ•°æ®é›†
        if self.config.getboolean("Logging", "verbose_console", fallback=True):
            # ç¡®ä¿è¿™äº›å±æ€§å­˜åœ¨
            base_categorical_count = len(getattr(self.data_preprocessor, 'base_categorical', []))
            base_numeric_count = len(getattr(self.data_preprocessor, 'base_numeric', []))
            target_features_count = len(getattr(self.data_preprocessor, 'target_features', []))
            algorithm = getattr(self.model_trainer, 'algorithm', 'lightgbm')
            print(f"â”œâ”€ åˆ†ç±»ç‰¹å¾æ•°é‡ï¼š{base_categorical_count}")
            print(f"â”œâ”€ æ•°å€¼ç‰¹å¾æ•°é‡ï¼š{base_numeric_count}")
            print(f"â”œâ”€ é¢„æµ‹ç›®æ ‡æ•°é‡ï¼š{target_features_count}")
            print(f"â”œâ”€ ç´¯è®¡æ ·æœ¬æ•°ï¼š{self.total_samples}")
            print(f"â”œâ”€ ä½¿ç”¨ç®—æ³•ï¼š{algorithm}")
            print(f"â””â”€ æ¨¡å‹çŠ¶æ€ï¼š{'å·²è®­ç»ƒ' if self.is_trained else 'æœªè®­ç»ƒ'}")
            print("=" * 60)

    def reload_config(self, new_config_path=None, reload_database=False):
        """
        åŠ¨æ€é‡è½½é…ç½®ï¼ˆä¸é‡å¯æœåŠ¡ï¼‰
        ä¿æŒåŸæœ‰æ¨¡å‹çŠ¶æ€ï¼Œåªæ›´æ–°é…ç½®å‚æ•°

        :param new_config_path: strï¼Œæ–°é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤Noneï¼ˆä½¿ç”¨å½“å‰è·¯å¾„ï¼‰
        :param reload_database: boolï¼Œæ˜¯å¦é‡è½½æ•°æ®åº“é…ç½®ï¼Œé»˜è®¤Falseï¼ˆé¿å…ä¸å¿…è¦çš„è¿æ¥é‡å»ºï¼‰
        :return: boolï¼Œé‡è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åŠ¨æ€é‡è½½ç³»ç»Ÿé…ç½®")

            # Step 1: å¤‡ä»½å…³é”®çŠ¶æ€
            current_models = self.models.copy() if self.models else {}
            current_total_samples = self.total_samples
            current_training_stats = self.training_stats.copy() if hasattr(self, 'training_stats') else []
            current_eval_history = self.eval_history.copy() if hasattr(self, 'eval_history') else []
            current_baseline_rmse = self.baseline_rmse if hasattr(self, 'baseline_rmse') else None
            current_is_trained = self.is_trained
            current_preprocessor = self.preprocessor
            current_training_features = self.training_features
            current_fitted_feature_order = self._fitted_feature_order
            current_locked_algorithm = getattr(self, 'locked_algorithm', None)
            current_modules = {
                'fault_calculator': self.fault_calculator,
                'regional_calculator': self.regional_calculator,
                'data_preprocessor': self.data_preprocessor,
                'model_trainer': self.model_trainer,
                'model_evaluator': self.model_evaluator,
                'model_manager': self.model_manager,
                'db': self.db
            }
            # Step 2: æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›äº†æ–°è·¯å¾„ï¼‰
            if new_config_path:
                self.config_path = new_config_path
                logger.info(f"åˆ‡æ¢åˆ°æ–°é…ç½®æ–‡ä»¶: {new_config_path}")

            # Step 3: é‡æ–°è¯»å–é…ç½®
            merged_config = configparser.ConfigParser()

            # é¦–å…ˆè¯»å–åŸºç¡€é…ç½® config.ini
            merged_config.read("config.ini", encoding="utf-8")
            logger.debug("åŸºç¡€é…ç½®æ–‡ä»¶ config.ini å·²åŠ è½½")

            # ç„¶åè¯»å–é˜¶æ®µé…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå®ƒä¼šè¦†ç›–åŸºç¡€é…ç½®ä¸­çš„ç›¸åŒé¡¹
            if self.config_path and self.config_path != "config.ini":
                stage_config_read = merged_config.read(self.config_path, encoding="utf-8")
                if stage_config_read:
                    logger.debug(f"é˜¶æ®µé…ç½®æ–‡ä»¶ {self.config_path} å·²åŠ è½½å¹¶åˆå¹¶")
                else:
                    logger.warning(f"é˜¶æ®µé…ç½®æ–‡ä»¶ {self.config_path} è¯»å–å¤±è´¥ï¼Œä»…ä½¿ç”¨åŸºç¡€é…ç½®")

            # æ›´æ–°å½“å‰é…ç½®å¯¹è±¡
            self.config = merged_config
            logger.debug("é…ç½®æ–‡ä»¶åˆå¹¶å®Œæˆ")

            # Step 3.1: ç®—æ³•é”å®šï¼ˆå­˜åœ¨å·²è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¿½ç•¥é…ç½®æ–‡ä»¶ä¸­çš„algorithmå˜æ›´ï¼‰
            locked = current_locked_algorithm or self.model_manager.get_locked_algorithm()
            if locked:
            # è¯»å–ç”¨æˆ·é…ç½®ä¸­çš„algorithmï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
                cfg_algo = merged_config.get("Model", "algorithm", fallback=locked).strip().lower()
                if cfg_algo != locked:
                   logger.warning(
                        f"é…ç½®æ–‡ä»¶algorithm={cfg_algo}å°†è¢«å¿½ç•¥ï¼›ç³»ç»Ÿå·²é”å®šç®—æ³•={locked}ï¼ˆå¯åŠ¨åä¸å¯åˆ‡æ¢ï¼‰"
                   )
                # å¼ºåˆ¶å†™å›åˆå¹¶åçš„é…ç½®ï¼Œç¡®ä¿åç»­é‡å»ºTrainerä½¿ç”¨é”å®šç®—æ³•
                if not merged_config.has_section("Model"):
                    merged_config.add_section("Model")
                merged_config.set("Model", "algorithm", locked)
                self.locked_algorithm = locked
            else:
                # æœªè®­ç»ƒæ¨¡å‹æ—¶ï¼Œå…è®¸ä»¥é…ç½®ä¸ºå‡†ï¼Œå¹¶è®°å½•ä¸ºé¢„æœŸé”å®šç®—æ³•
                self.locked_algorithm = merged_config.get("Model", "algorithm",fallback="lightgbm").strip().lower()

            # Step 4: é‡æ–°åˆå§‹åŒ–é…ç½®å·¥å…·å’Œå„æ¨¡å—,ä½¿ç”¨åˆå¹¶åçš„é…ç½®å¯¹è±¡æ¥åˆå§‹åŒ–å„æ¨¡å—
            self.config_utils = ConfigUtils(self.config_path)
            # é‡æ–°åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å—
            self.fault_calculator = FaultCalculator(self.config_path)
            self.regional_calculator = RegionalMeasureCalculator(self.config_path)
            self.data_preprocessor = DataPreprocessor(self.config_path)
            self.model_trainer = ModelTrainer(self.config)
            self.model_evaluator = ModelEvaluator(self.config_path)
            self.model_manager = ModelManager(self.model_dir)
            # ------------------------------------------------------------------
            # å¢é‡è®­ç»ƒçª—å£å‚æ•°ï¼ˆç”¨äºå•å¤©æ‰¹æ¬¡è‡ªåŠ¨è¡¥å†å²çª—å£ï¼Œé¿å…æ—¶åºæ¼‚ç§»ï¼‰
            # ------------------------------------------------------------------
            try:
                self.incremental_lookback_days = self.config.getint(
                    "Model", "incremental_lookback_days", fallback=7
                )
            except Exception:
                self.incremental_lookback_days = 7

            try:
                self.incremental_window_limit = self.config.getint(
                    "Model", "incremental_window_limit", fallback=3000
                )
            except Exception:
                self.incremental_window_limit = 3000

            logger.info(
                f"å¢é‡è®­ç»ƒçª—å£å‚æ•°åŠ è½½å®Œæˆï¼š"
                f"lookback_days={self.incremental_lookback_days}, "
                f"window_limit={self.incremental_window_limit}"
            )

            # Step 5: æ¡ä»¶æ€§é‡è½½æ•°æ®åº“é…ç½®
            if reload_database:
                logger.info("é‡è½½æ•°æ®åº“é…ç½®ï¼ˆå°†é‡å»ºæ•°æ®åº“è¿æ¥ï¼‰")
                db_reload_success = self.db.reload_config(self.config_path)
                if not db_reload_success:
                    logger.error("æ•°æ®åº“é…ç½®é‡è½½å¤±è´¥ï¼Œä½†ç»§ç»­å…¶ä»–é…ç½®é‡è½½")
            else:
                logger.info("è·³è¿‡æ•°æ®åº“é…ç½®é‡è½½ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥ï¼‰")
            # Step 6: é‡æ–°åŠ è½½æ¨¡å‹æ ¸å¿ƒå‚æ•°
            self.full_train_threshold = self.config_utils._get_config_value("Model", "full_train_threshold", 6,
                                                                            is_int=True)
            self.min_train_samples = self.config_utils._get_config_value("Model", "min_train_samples", 6,
                                                                         is_int=True)
            # Step 7: æ¢å¤å…³é”®çŠ¶æ€
            self.models = current_models
            self.total_samples = current_total_samples
            self.training_stats = current_training_stats
            self.eval_history = current_eval_history
            self.baseline_rmse = current_baseline_rmse
            self.is_trained = current_is_trained
            self.preprocessor = current_preprocessor
            self.training_features = current_training_features
            self._fitted_feature_order = current_fitted_feature_order

            # Step 8: åŒæ­¥é¢„å¤„ç†å™¨çŠ¶æ€
            if hasattr(self.data_preprocessor, 'is_trained'):
                self.data_preprocessor.is_trained = current_is_trained
            if hasattr(self.data_preprocessor, 'training_features') and self.training_features:
                self.data_preprocessor.training_features = self.training_features
            if hasattr(self, 'model_trainer'):
                self.model_trainer.config_filename = os.path.basename(self.config_path)
            logger.info("é…ç½®åŠ¨æ€é‡è½½å®Œæˆï¼Œæ‰€æœ‰æ¨¡å—å·²æ›´æ–°")
            self._print_result("é…ç½®åŠ¨æ€é‡è½½æˆåŠŸ")

            # è¾“å‡ºæ–°çš„å…³é”®å‚æ•°å€¼
            if self.config.getboolean("Logging", "verbose_console", fallback=True):
                print(f"â”œâ”€ æ–°çš„å…¨é‡è®­ç»ƒé˜ˆå€¼: {self.full_train_threshold}")
                print(f"â”œâ”€ æ–°çš„æœ€å°æ ·æœ¬æ•°: {self.min_train_samples}")
                print(f"â”œâ”€ æ–°çš„æ ‘æ•°é‡: {self.model_trainer.n_estimators}")
                print(f"â”œâ”€ æ–°çš„å­¦ä¹ ç‡: {self.model_trainer.learning_rate}")
                if reload_database:
                    print(f"â””â”€ æ•°æ®åº“é…ç½®å·²é‡è½½")
                else:
                    print(f"â””â”€ æ•°æ®åº“é…ç½®æœªé‡è½½ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥ï¼‰")

            return True


        except Exception as e:
            logger.error(f"é…ç½®åŠ¨æ€é‡è½½å¤±è´¥ï¼Œæ­£åœ¨æ¢å¤çŠ¶æ€ï¼š{str(e)}", exc_info=True)
            # æ¢å¤æ¨¡å—çŠ¶æ€
            self.fault_calculator = current_modules['fault_calculator']
            self.regional_calculator = current_modules['regional_calculator']
            self.data_preprocessor = current_modules['data_preprocessor']
            self.model_trainer = current_modules['model_trainer']
            self.model_evaluator = current_modules['model_evaluator']
            self.model_manager = current_modules['model_manager']
            self.db = current_modules['db']
            # æ¢å¤ç®—æ³•é”å®šçŠ¶æ€
            self.locked_algorithm = current_locked_algorithm
            self._print_result(f"é…ç½®é‡è½½å¤±è´¥ï¼š{str(e)}")
            return False

    def _print_header(self, title):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_header(title)

    def _print_step(self, msg):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_step(msg)

    def _print_result(self, msg):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_result(msg)

    def _load_model(self):
        """åŠ è½½å·²æœ‰æ¨¡å‹ç»„ä»¶"""
        self._print_header("åŠ è½½å·²æœ‰æ¨¡å‹")
        try:
            # ç¡®ä¿target_featureså±æ€§å­˜åœ¨
            target_features = getattr(self.data_preprocessor, 'target_features', [])
            if not target_features:
                logger.warning("ç›®æ ‡ç‰¹å¾åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
                self.is_trained = False
                return

            (self.preprocessor, self.training_features,
             self.models, self.is_trained) = self.model_manager.load_model(target_features)

            if self.is_trained:
                self.data_preprocessor.is_trained = True
                self.data_preprocessor.training_features = self.training_features
                self._print_step("æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                self._print_step("æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æœªè®­ç»ƒï¼Œéœ€ä»å¤´è®­ç»ƒ")
        except Exception as e:
            self.is_trained = False
            logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}", exc_info=True)
            self._print_step(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼Œéœ€ä»å¤´è®­ç»ƒ")
        finally:
            if self.config.getboolean("Logging", "verbose_console", fallback=True):
                print("-" * 60)

    def calculate_fault_influence_strength(self, data):
        """è®¡ç®—æ–­å±‚å½±å“ç³»æ•°ï¼ˆå§”æ‰˜ç»™FaultCalculatorï¼‰"""
        return self.fault_calculator.calculate_fault_influence_strength(data, self.db)

    def calculate_regional_measure_strength(self, measures):
        """è®¡ç®—åŒºåŸŸæªæ–½å¼ºåº¦ï¼ˆå§”æ‰˜ç»™RegionalMeasureCalculatorï¼‰"""
        return self.regional_calculator.calculate_regional_measure_strength(measures)

    def _preprocess_data(self, data, is_training=True):
        """æ•°æ®é¢„å¤„ç†ï¼ˆå§”æ‰˜ç»™DataPreprocessorï¼‰"""
        if is_training:
            df, training_features = self.data_preprocessor.preprocess_data(
                data, is_training, self.fault_calculator, self.db
            )
            self.training_features = training_features
            return df
        else:
            return self.data_preprocessor.preprocess_data(
                data, is_training, self.fault_calculator, self.db
            )

    def _print_training_diagnosis(self):
        """
        æ–°å¢ï¼šæ‰“å°è®­ç»ƒè¯Šæ–­ç»“æœå’Œå‚æ•°å»ºè®®
        ä¸ä¿®æ”¹åŸæœ‰è®­ç»ƒæµç¨‹
        """
        training_details = self.model_trainer.get_last_training_diagnostics()
        if not training_details:
            return

        target_performance = training_details.get('target_performance', {})
        suggestions = training_details.get('parameter_suggestions', [])

        self._print_header("æ¨¡å‹è®­ç»ƒè¯Šæ–­ç»“æœ")

        # æ‰“å°å„ç›®æ ‡æ€§èƒ½
        for target, perf in target_performance.items():
            status = "âœ… è‰¯å¥½"
            if perf.get('is_overfitting', False):
                status = "âš ï¸ è¿‡æ‹Ÿåˆ"
            elif perf.get('is_underfitting', False):
                status = "ğŸ“‰ æ¬ æ‹Ÿåˆ"

            validation_note = "(éªŒè¯é›†)" if perf.get('use_validation', False) else "(è®­ç»ƒé›†)"
            self._print_step(
                f"{target}: è®­ç»ƒRMSE={perf['train_rmse']}, "
                f"{validation_note}RMSE={perf['val_rmse']}, "
                f"è¿‡æ‹Ÿåˆæ¯”ç‡={perf['overfitting_ratio']} {status}"
            )

        # æ‰“å°å‚æ•°å»ºè®®
        if suggestions:
            self._print_header("å‚æ•°è°ƒæ•´å»ºè®®")
            for suggestion in suggestions:
                self._print_step(suggestion)

    def _resolve_incremental_lookback_days(self, default_days: int = 10) -> int:
        """
        å¢é‡è®­ç»ƒ lookback_days çš„â€œé€’è¿›ç­–ç•¥â€ï¼š
          - æ”¯æŒé…ç½® incremental_lookback_days_schedule = 10,14,21
          - æ”¯æŒé…ç½® incremental_lookback_step_samples = 1500ï¼ˆç´¯è®¡æ ·æœ¬æ¯å¢åŠ è¿™ä¹ˆå¤šï¼Œlookbackå‡çº§ä¸€çº§ï¼‰
          - è‹¥é…ç½®ç¼ºå¤±ï¼Œåˆ™å›é€€ä¸º incremental_lookback_days æˆ– default_days
        """
        # 1) schedule
        schedule = None
        try:
            s = self.config.get("Model", "incremental_lookback_days_schedule", fallback="").strip()
            if s:
                schedule = [int(x.strip()) for x in s.split(",") if x.strip()]
                schedule = [x for x in schedule if x > 0]
        except Exception:
            schedule = None

        # 2) step
        step_samples = None
        try:
            step_samples = self.config.getint("Model", "incremental_lookback_step_samples", fallback=1500)
            if step_samples <= 0:
                step_samples = 1500
        except Exception:
            step_samples = 1500

        # 3) fallback base
        base_days = default_days
        try:
            base_days = self.config.getint("Model", "incremental_lookback_days", fallback=default_days)
            if base_days <= 0:
                base_days = default_days
        except Exception:
            base_days = default_days

        # 4) choose
        if not schedule:
            return int(base_days)

        try:
            total = int(getattr(self, "total_samples", 0) or 0)
        except Exception:
            total = 0

        # level by total samples
        idx = 0
        try:
            idx = int(total // step_samples)
        except Exception:
            idx = 0
        if idx < 0:
            idx = 0
        if idx > len(schedule) - 1:
            idx = len(schedule) - 1

        # ensure not smaller than base
        chosen = int(schedule[idx])
        if chosen < int(base_days):
            chosen = int(base_days)
        return chosen

    def _smooth_training_targets(self, train_df: pd.DataFrame, target_features: list,
                                 group_col: str = "spatiotemporal_group") -> np.ndarray:
        """
        ä»…è®­ç»ƒé˜¶æ®µï¼šå¯¹ gas_emission_velocity_q åšè½»å¾®å¹³æ»‘ï¼Œè¿”å›ç”¨äºè®­ç»ƒçš„ yï¼ˆnumpyï¼‰ã€‚
        - ä¸ä¿®æ”¹ train_dfï¼ˆä¿è¯å…¥åº“çš„åŸå§‹æ•°æ®ä¸å˜ï¼‰
        - è‹¥ç¼ºåˆ—/å¼‚å¸¸ï¼šç›´æ¥å›é€€åŸå§‹ y
        """
        y = train_df[target_features].values

        # æ²¡æœ‰ q å°±ä¸å¤„ç†
        if "gas_emission_velocity_q" not in target_features:
            return y

        try:
            enable = self.config.getboolean("Model", "smooth_q_target", fallback=True)
        except Exception:
            enable = True
        if not enable:
            return y

        # alpha è¶Šå°è¶Šå¹³æ»‘ï¼ˆå»ºè®® 0.15~0.30ï¼‰
        try:
            alpha = self.config.getfloat("Model", "q_smooth_alpha", fallback=0.22)
        except Exception:
            alpha = 0.22
        if alpha <= 0 or alpha >= 1:
            alpha = 0.22

        # éœ€è¦åˆ†ç»„ + æŒ‰æ—¥æœŸæ’åº
        if group_col not in train_df.columns:
            return y
        if "measurement_date_parsed" in train_df.columns:
            order_col = "measurement_date_parsed"
        elif "measurement_date" in train_df.columns:
            order_col = "measurement_date"
        else:
            return y

        try:
            q_idx = target_features.index("gas_emission_velocity_q")
        except Exception:
            return y

        try:
            tmp = train_df[[group_col, order_col, "gas_emission_velocity_q"]].copy()
            tmp[order_col] = pd.to_datetime(tmp[order_col], errors="coerce")
            tmp = tmp.sort_values([group_col, order_col], kind="mergesort")

            # å¯¹æ¯ä¸ªç»„åš EWMï¼ˆä»…ç”¨å†å²æ–¹å‘ï¼‰
            smoothed = (
                tmp.groupby(group_col)["gas_emission_velocity_q"]
                .apply(lambda s: s.ewm(alpha=alpha, adjust=False).mean())
                .reset_index(level=0, drop=True)
            )
            smoothed = smoothed.replace([np.inf, -np.inf], np.nan)

            # å›å¡«åˆ° yï¼ˆæŒ‰ tmp çš„è¡Œé¡ºåºå¯¹åº” train_df çš„é¡ºåºä¸ä¸€å®šä¸€è‡´ï¼‰
            # æ‰€ä»¥æˆ‘ä»¬æŒ‰ index å¯¹é½å›å¡«
            smoothed = smoothed.reindex(tmp.index)
            q_s = smoothed.reindex(train_df.index)  # å†å¯¹é½å› train_df åŸç´¢å¼•
            q_s = q_s.fillna(train_df["gas_emission_velocity_q"]).values

            y2 = np.array(y, copy=True)
            y2[:, q_idx] = q_s
            return y2
        except Exception:
            return y

    def train(self, data, epochs=1):
        """
        å…¬å¼€æ–¹æ³•ï¼šæ¨¡å‹è®­ç»ƒæ¥å£
        """
        with self.file_lock:
            self._print_header("æ¨¡å‹è®­ç»ƒå¼€å§‹")
            train_start = datetime.now()
            initial_samples = self.total_samples
            db_conn = None
            db_trans = None
            custom_create_time = None
            saved_count = 0

            try:
                # Step 1: æ•°æ®é¢„å¤„ç† - æ·»åŠ è¯¦ç»†æ—¥å¿—å’Œé”™è¯¯å¤„ç†
                logger.info(f"å¼€å§‹æ•°æ®é¢„å¤„ç†ï¼Œè¾“å…¥æ•°æ®æ ·æœ¬æ•°: {len(data) if isinstance(data, list) else 'unknown'}")

                try:
                    df = self._preprocess_data(data, is_training=True)
                    logger.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼ŒDataFrameå½¢çŠ¶: {df.shape}")
                except Exception as e:
                    logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
                    raise ValueError(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")

                # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
                logger.info(f"DataFrameåˆ—å: {list(df.columns)}")
                logger.info(f"è®­ç»ƒç‰¹å¾: {self.training_features}")
                logger.info(f"ç›®æ ‡ç‰¹å¾: {self.data_preprocessor.target_features}")

                # ============ å…ˆæ‰§è¡Œï¼šè‡ªåŠ¨é…ç½®åˆ‡æ¢é€»è¾‘ï¼ˆç¡®ä¿è®­ç»ƒç‰¹å¾ä»¥æœ€ç»ˆé…ç½®ä¸ºå‡†ï¼‰ ============
                # åˆ¤æ–­æ˜¯å¦åˆæ¬¡è®­ç»ƒï¼ˆæ¨¡å‹æœªè®­ç»ƒä¸”æ•°æ®åº“æ ·æœ¬æ•°ä¸º0ï¼‰
                is_initial_training = not self.is_trained and initial_samples == 0

                # åˆ¤æ–­æ•°æ®é‡å¤§å°ï¼ˆä½¿ç”¨å…¨é‡è®­ç»ƒé˜ˆå€¼ä½œä¸ºåˆ¤æ–­æ ‡å‡†ï¼‰
                is_large_data = len(df) >= self.full_train_threshold

                # è‡ªåŠ¨é…ç½®åˆ‡æ¢å†³ç­–
                if is_initial_training and is_large_data:
                    # åˆæ¬¡å¤§é‡æ•°æ®è®­ç»ƒ â†’ ä½¿ç”¨ phase1 é…ç½®
                    target_config = "config_phase1.ini"
                    reason = "åˆæ¬¡å¤§é‡æ•°æ®è®­ç»ƒ"
                elif self.is_trained and not is_large_data:
                    # åç»­å°‘é‡æ•°æ®å¢é‡è®­ç»ƒ â†’ ä½¿ç”¨ phase2 é…ç½®
                    target_config = "config_phase2.ini"
                    reason = "å°‘é‡æ•°æ®å¢é‡è®­ç»ƒ"
                else:
                    # å…¶ä»–æƒ…å†µä¿æŒå½“å‰é…ç½®
                    target_config = None
                    reason = "ä¿æŒå½“å‰é…ç½®"

                # æ‰§è¡Œé…ç½®åˆ‡æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if target_config and getattr(self, 'current_config', None) != target_config:
                    logger.info(f"è‡ªåŠ¨é…ç½®åˆ‡æ¢ï¼š{reason} â†’ {target_config}")
                    success = self.reload_config(target_config)
                    if success:
                        self.current_config = target_config
                        self.model_trainer.config_filename = os.path.basename(target_config)
                        self._print_step(f"âœ… é…ç½®å·²åˆ‡æ¢ï¼š{target_config}ï¼ˆ{reason}ï¼‰")
                    else:
                        logger.error(f"é…ç½®åˆ‡æ¢å¤±è´¥ï¼š{target_config}")
                        self._print_step(f"âŒ é…ç½®åˆ‡æ¢å¤±è´¥ï¼š{target_config}")
                elif target_config:
                    logger.debug(f"é…ç½®å·²æ˜¯æœ€æ–°ï¼š{target_config}")
                else:
                    logger.debug(f"æ— éœ€åˆ‡æ¢é…ç½®ï¼š{reason}")
                # ============ è‡ªåŠ¨é…ç½®åˆ‡æ¢é€»è¾‘ç»“æŸ ============

                # é…ç½®åˆ‡æ¢åå†æ‰“å°ä¸€æ¬¡ï¼Œä¾¿äºå®¡è®¡æœ€ç»ˆç”Ÿæ•ˆçš„ç‰¹å¾é…ç½®
                logger.info(f"[é…ç½®åˆ‡æ¢å] è®­ç»ƒç‰¹å¾: {self.training_features}")
                # ============ å…³é”®è¡¥ä¸ï¼šå¼ºåˆ¶â€œç‰¹å¾åç¨³å®šåŒ–â€ï¼ˆé¿å… advance_rate_mining è¿™ç±»æ–°åˆ—å¯¼è‡´è®­ç»ƒ/è¯„ä¼°/DBå…¨é“¾è·¯å´©æºƒï¼‰ ============
                try:
                    if self.training_features:
                        # 1) å¦‚æœé…ç½®é‡Œè¯¯å†™äº† advance_rate_miningï¼šä¸€å¾‹æ˜ å°„å› advance_rateï¼ˆä¸æ–°å¢DBåˆ—ï¼Œæœ€ç¨³ï¼‰
                        if "advance_rate_mining" in self.training_features:
                            self.training_features = ["advance_rate" if x == "advance_rate_mining" else x for x in
                                                      self.training_features]
                            logger.warning(
                                "æ£€æµ‹åˆ° training_features åŒ…å« advance_rate_miningï¼Œå·²å¼ºåˆ¶æ˜ å°„ä¸º advance_rateï¼ˆé¿å…ç¼ºåˆ—/Unknown columnï¼‰")

                        # 2) å½»åº•å‰”é™¤ gas_emission_q ç›¸å…³åˆ—ï¼ˆä½ å½“å‰ç³»ç»Ÿä¸è®­ç»ƒå®ƒï¼Œé¿å…å†æ¬¡è§¦å‘ not in index / Unknown columnï¼‰
                        banned = {
                            "gas_emission_q",
                            "gas_emission_q_trend",
                            "gas_emission_q_historical_mean",
                        }
                        before = list(self.training_features)
                        self.training_features = [x for x in self.training_features if x not in banned]
                        if len(before) != len(self.training_features):
                            logger.warning(
                                f"training_features ä¸­å‘ç° gas_emission_q ç›¸å…³åˆ—ï¼Œå·²å‰”é™¤ï¼š{sorted(set(before) - set(self.training_features))}")

                        # åŒæ­¥ç»™é¢„å¤„ç†å™¨ï¼ˆé¢„æµ‹/è¯„ä¼°éœ€è¦å¯¹é½ï¼‰
                        if hasattr(self.data_preprocessor, "training_features"):
                            self.data_preprocessor.training_features = self.training_features
                except Exception as _e:
                    logger.warning(f"ç‰¹å¾åç¨³å®šåŒ–è¡¥ä¸æ‰§è¡Œå¤±è´¥ï¼ˆå·²å¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰ï¼š{repr(_e)}", exc_info=True)
                # ============ è¡¥ä¸ç»“æŸ ============

                # ============ å¼ºåˆ¶å‰”é™¤ gas_emission_q ç›¸å…³ç‰¹å¾ï¼ˆæ ¹æ²»ç¼ºåˆ—å¯¼è‡´è®­ç»ƒå¤±è´¥ï¼‰ ============
                try:
                    if self.training_features:
                        before = list(self.training_features)
                        self.training_features = [
                            f for f in self.training_features
                            if not (f == "gas_emission_q"
                                    or f.startswith("gas_emission_q_")
                                    or "gas_emission_q_" in f)
                        ]
                        removed = [f for f in before if f not in self.training_features]
                        if removed:
                            logger.warning(f"å·²å¼ºåˆ¶å‰”é™¤ {len(removed)} ä¸ª gas_emission_q ç›¸å…³ç‰¹å¾ï¼š{removed}")
                            logger.info(f"å‰”é™¤åè®­ç»ƒç‰¹å¾æ•°ï¼š{len(before)} -> {len(self.training_features)}")
                            logger.info(f"å‰”é™¤åè®­ç»ƒç‰¹å¾åˆ—è¡¨ï¼š{self.training_features}")

                        # åŒæ­¥ç»™ data_preprocessorï¼ˆä¿è¯è®­ç»ƒ/é¢„æµ‹/è¯„ä¼°ä¸€è‡´ï¼‰
                        if hasattr(self.data_preprocessor, "training_features"):
                            self.data_preprocessor.training_features = self.training_features
                except Exception as _e:
                    logger.warning(f"å¼ºåˆ¶å‰”é™¤ gas_emission_q ç‰¹å¾å¤±è´¥ï¼ˆå·²å¿½ç•¥ï¼‰ï¼š{repr(_e)}", exc_info=True)
                # ============ å¼ºåˆ¶å‰”é™¤ç»“æŸ ============

                # ============ æ–°å¢ï¼šè‡ªåŠ¨ç‰¹å¾é™çº§ / è‡ªåŠ¨æ¢å¤ï¼ˆå‡çº§ï¼‰ ============
                # å†·å¯åŠ¨é˜¶æ®µå¸¸è§ï¼šdays_* / distance_time_interaction / advance_rate æ’ä¸º0æˆ–æ— ä¿¡æ¯é‡ï¼Œè‡ªåŠ¨å‰”é™¤é™å™ªï¼›
                # å½“åç»­æ•°æ®å…·å¤‡æ—¶é—´è·¨åº¦/æ¨è¿›ä¿¡æ¯æ—¶è‡ªåŠ¨æ¢å¤ã€‚
                try:
                    if not self.training_features:
                        raise ValueError("training_featuresä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œè‡ªåŠ¨ç‰¹å¾é™çº§")

                    # å›ºåŒ–â€œé…ç½®å±‚é¢â€çš„å…¨é‡ç‰¹å¾ï¼ˆé¦–æ¬¡è¿›å…¥trainæ—¶è®°å½•ä¸€æ¬¡ï¼‰
                    if not hasattr(self, "_configured_training_features") or not self._configured_training_features:
                        self._configured_training_features = list(self.training_features)
                    degrade_candidates = [
                        # æ—¶é—´é”šå®šç±»ç‰¹å¾ç»å¯¹ä¸å…è®¸è¢«é™çº§
                        # "days_since_start",
                        # "days_in_workface",
                        # "distance_time_interaction",

                        # åªå…è®¸å¯¹æ¨è¿›é€Ÿç‡åšé€€åŒ–åˆ¤æ–­
                        "advance_rate",
                    ]
                    def _is_degenerate_feature(_df: pd.DataFrame, col: str):
                        """åˆ¤æ–­ç‰¹å¾æ˜¯å¦é€€åŒ–ï¼›è¿”å›(æ˜¯å¦é€€åŒ–, åŸå› )"""
                        if col not in _df.columns:
                            return True, "ç¼ºåˆ—"
                        s = _df[col]
                        # ç»Ÿä¸€å¤„ç†inf
                        try:
                            if pd.api.types.is_numeric_dtype(s):
                                s = s.replace([np.inf, -np.inf], np.nan)
                        except Exception:
                            pass
                        # å…¨ç©º
                        if s.isna().all():
                            return True, "å…¨ç¼ºå¤±"
                        # å¸¸æ•°åˆ—ï¼ˆå«å…¨ä¸º0ï¼‰
                        try:
                            nunq = int(s.nunique(dropna=True))
                        except Exception:
                            nunq = 2  # ä¿å®ˆï¼šä¸åˆ¤é€€åŒ–
                        if nunq <= 1:
                            if pd.api.types.is_numeric_dtype(s):
                                try:
                                    if (s.fillna(0) == 0).all():
                                        return True, "å¸¸æ•°åˆ—ï¼ˆå…¨ä¸º0ï¼‰"
                                except Exception:
                                    pass
                            return True, "å¸¸æ•°åˆ—ï¼ˆnunique<=1ï¼‰"
                        return False, "OK"
                    # 1) è‡ªåŠ¨é™çº§ï¼šå‰”é™¤é€€åŒ–ç‰¹å¾
                    removed = []
                    reasons_map = {}
                    for c in degrade_candidates:
                        deg, why = _is_degenerate_feature(df, c)
                        if deg and c in self.training_features:
                            removed.append(c)
                            reasons_map[c] = why
                    # 2) è‡ªåŠ¨æ¢å¤ï¼šå½“é€€åŒ–ç‰¹å¾åœ¨æ–°æ•°æ®ä¸­æœ‰ä¿¡æ¯é‡åˆ™æ¢å¤ï¼ˆæŒ‰é…ç½®é¡ºåºï¼‰
                    restored = []
                    for c in degrade_candidates:
                        if c in getattr(self, "_configured_training_features", []) and c not in self.training_features:
                            deg, _ = _is_degenerate_feature(df, c)
                            if not deg:
                                restored.append(c)
                    if removed or restored:
                        before_cnt = len(self.training_features)
                        active = list(self.training_features)
                        # å…ˆæ¢å¤ï¼ˆæŒ‰é…ç½®é¡ºåºï¼‰
                        if restored:
                            cfg = list(self._configured_training_features)
                            active_set = set(active) | set(restored)
                            active = [x for x in cfg if x in active_set]
                        # å†å‰”é™¤
                        if removed:
                            active = [x for x in active if x not in set(removed)]
                        self.training_features = active
                        # åŒæ­¥åˆ°é¢„å¤„ç†å™¨ï¼ˆé¢„æµ‹/è¯„ä¼°å¯¹é½éœ€è¦ï¼‰
                        if hasattr(self.data_preprocessor, "training_features"):
                            self.data_preprocessor.training_features = self.training_features
                        after_cnt = len(self.training_features)
                        if removed:
                            logger.warning(
                                f"è‡ªåŠ¨ç‰¹å¾é™çº§ï¼šå‰”é™¤{len(removed)}ä¸ªé€€åŒ–ç‰¹å¾ -> {removed}ï¼ŒåŸå› ={reasons_map}"
                            )
                        if restored:
                            logger.info(f"è‡ªåŠ¨ç‰¹å¾æ¢å¤ï¼šæ¢å¤{len(restored)}ä¸ªç‰¹å¾ -> {restored}")
                        logger.info(f"æœ¬æ¬¡è®­ç»ƒç”Ÿæ•ˆç‰¹å¾æ•°ï¼š{before_cnt} -> {after_cnt}")
                        logger.info(f"æœ¬æ¬¡è®­ç»ƒç”Ÿæ•ˆç‰¹å¾åˆ—è¡¨ï¼š{self.training_features}")
                except Exception as _e:
                    logger.warning(f"è‡ªåŠ¨ç‰¹å¾é™çº§/æ¢å¤æ‰§è¡Œå¤±è´¥ï¼ˆå·²å¿½ç•¥ï¼‰ï¼š{repr(_e)}", exc_info=True)
                # ============ è‡ªåŠ¨ç‰¹å¾é™çº§ / è‡ªåŠ¨æ¢å¤ç»“æŸ ============
                # ============ ç‰¹å¾åˆ—åˆ«åå½’ä¸€ + ç¼ºåˆ—å…œåº•ï¼ˆé˜²æ­¢KeyErrorï¼‰ ============
                try:
                    # 1) åˆ«åæ˜ å°„ï¼šæŠŠå¯èƒ½å­˜åœ¨çš„åˆ—ç»Ÿä¸€åˆ°è®­ç»ƒç‰¹å¾éœ€è¦çš„åˆ—å
                    #    ä½ ç°åœ¨çš„DataPreprocessorç”Ÿæˆçš„æ˜¯ advance_rateï¼ˆæ¨èï¼‰ï¼Œä½†é…ç½®é‡Œå¯èƒ½å†™äº† advance_rate_mining
                    alias_map = {
                        "advance_rate_mining": "advance_rate",
                        # å¦‚æœä½ å†å²ç‰ˆæœ¬é‡Œè¿˜æœ‰åˆ«åï¼Œä¹Ÿå¯ä»¥ç»§ç»­åŠ ï¼š
                        # "advance_rate_other": "advance_rate",
                    }

                    for want, have in alias_map.items():
                        if want in getattr(self, "training_features",
                                           []) and want not in df.columns and have in df.columns:
                            df[want] = df[have]
                            logger.info(f"ç‰¹å¾åˆ«åå½’ä¸€ï¼šä½¿ç”¨ {have} å¡«å…… {want}")

                    # 2) æœ€ç»ˆå…œåº•ï¼šè®­ç»ƒç‰¹å¾ç¼ºåˆ—åˆ™è¡¥0ï¼ˆæ¯”ç›´æ¥æŠ¥é”™æ›´ç¬¦åˆä½ çš„â€œç³»ç»Ÿä¸èƒ½è½»æ˜“å¤±è´¥â€åŸåˆ™ï¼‰
                    if self.training_features:
                        missing_now = [f for f in self.training_features if f not in df.columns]
                        if missing_now:
                            logger.warning(f"è®­ç»ƒç‰¹å¾ç¼ºå¤±{len(missing_now)}åˆ—ï¼Œå°†è¡¥0ï¼š{missing_now}")
                            for f in missing_now:
                                df[f] = 0.0

                except Exception as _e:
                    logger.warning(f"ç‰¹å¾åˆ«åå½’ä¸€/ç¼ºåˆ—å…œåº•å¤±è´¥ï¼ˆå·²å¿½ç•¥ï¼‰ï¼š{repr(_e)}", exc_info=True)
                # ============ ç»“æŸ ============

                if len(df) < self.min_train_samples:
                    msg = f"æ ·æœ¬æ•° {len(df)} < æœ€å°è®­ç»ƒæ ·æœ¬æ•° {self.min_train_samples}ï¼Œè·³è¿‡è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": len(df), "training_performed": False}
                    }
                # å› ä¸ºå¢é‡è®­ç»ƒä¼šå›ælookbackçª—å£ï¼Œæœ€ç»ˆè®­ç»ƒé›†(train_df)å¯èƒ½é€šè¿‡DBè¡¥é½å¢å¼ºç‰¹å¾åˆ—
                missing_features = []
                if self.training_features:
                    missing_features = [f for f in self.training_features if f not in df.columns]
                if missing_features:
                    logger.warning(f"æœ¬æ‰¹è®­ç»ƒdfç¼ºå°‘ç‰¹å¾(å¯èƒ½ç”±çª—å£train_dfè¡¥é½)ï¼š{missing_features}")
                    logger.debug(f"æœ¬æ‰¹dfå¯ç”¨åˆ—: {list(df.columns)}")
                missing_targets = []
                if self.data_preprocessor.target_features:
                    missing_targets = [t for t in self.data_preprocessor.target_features if t not in df.columns]
                if missing_targets:
                    logger.error(f"è®­ç»ƒæ•°æ®ç¼ºå°‘ç›®æ ‡ç‰¹å¾: {missing_targets}")
                    raise ValueError(f"è®­ç»ƒæ•°æ®ç¼ºå°‘ç›®æ ‡ç‰¹å¾: {missing_targets}")
                # Step 2: å¼€å¯æ•°æ®åº“äº‹åŠ¡
                db_conn = self.db._get_connection()
                db_trans = db_conn.begin()
                logger.info("æ•°æ®åº“äº‹åŠ¡å·²å¼€å¯ï¼Œå‡†å¤‡ä¿å­˜è®­ç»ƒæ•°æ®")
                # Step 3: ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
                custom_create_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
                saved_count = self.db.save_training_data(
                    df=df,
                    conn=db_conn,
                    trans=db_trans,
                    custom_create_time=custom_create_time
                )
                if saved_count == 0:
                    raise ValueError("æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥ï¼ˆä¿å­˜æ¡æ•°ä¸º0ï¼‰")
                logger.info(f"äº‹åŠ¡ä¸­æ’å…¥ {saved_count} æ¡è®­ç»ƒæ•°æ®ï¼ˆæœªæäº¤ï¼‰")
                # Step 4: åˆ¤æ–­è®­ç»ƒæ¨¡å¼ï¼ˆå…ˆåˆ¤æ–­æ¨¡å¼ï¼Œå†å†³å®šæ˜¯å¦å…è®¸é‡å»ºé¢„å¤„ç†å™¨ï¼‰
                current_total = initial_samples + len(df)
                threshold_hit = (current_total % self.full_train_threshold == 0)
                # ä¼ é€’æ•°æ®é‡ä¿¡æ¯çš„æ€§èƒ½æ£€æŸ¥
                perf_trigger = self.model_evaluator._performance_trigger_check(
                    self.eval_history,
                    self.baseline_rmse,
                    len(df)  # ä¼ é€’å½“å‰è®­ç»ƒæ•°æ®é‡
                )
                if perf_trigger:
                    do_full_train = True
                    reason = "æ€§èƒ½ä¸‹é™è§¦å‘"
                elif threshold_hit:
                    do_full_train = True
                    reason = "æ ·æœ¬æ•°è¾¾é˜ˆå€¼è§¦å‘"
                elif not self.is_trained:
                    do_full_train = True
                    # åªæœ‰â€œå†·å¯åŠ¨â€æ‰å«é¦–æ¬¡è®­ç»ƒ
                    if initial_samples == 0:
                        reason = "é¦–æ¬¡è®­ç»ƒ"
                    else:
                        reason = "å…¨é‡è®­ç»ƒï¼ˆæ¨¡å‹æœªå°±ç»ª/æœªå‘å¸ƒï¼‰"
                else:
                    do_full_train = False
                    reason = "å¢é‡è®­ç»ƒ"
                self._print_step(f"è®­ç»ƒæ¨¡å¼åˆ¤æ–­ï¼š{reason}")
                # Step 5: æ„å»ºè®­ç»ƒé›†ï¼ˆå¢é‡è®­ç»ƒï¼šåªè¦è¿›å…¥å¢é‡æ¨¡å¼å°±å¼ºåˆ¶lookbackçª—å£ï¼Œç¡®ä¿å¿…ç„¶ç”Ÿæ•ˆï¼‰
                train_df = df
                if (not do_full_train) and self.is_trained:
                    # è¯»å–çª—å£å‚æ•°
                    try:
                        lookback_days = self._resolve_incremental_lookback_days(default_days=10)
                    except Exception:
                        lookback_days = 14
                    try:
                        window_limit = self.config.getint("Model", "incremental_window_limit", fallback=2000)
                    except Exception:
                        window_limit = 2000
                    # ä»¥â€œæœ¬æ‰¹æ¬¡æœ€å¤§æ—¥æœŸâ€ä½œä¸ºçª—å£ä¸Šç•Œï¼ˆä¿è¯åŒäº‹åŠ¡æœªæäº¤æ•°æ®ä¹Ÿèƒ½çº³å…¥ï¼‰
                    max_date = None
                    try:
                        if "measurement_date" in df.columns:
                            _mx = pd.to_datetime(df["measurement_date"], errors="coerce").max()
                            if pd.notna(_mx):
                                max_date = str(_mx.date())
                    except Exception:
                        max_date = None
                    workface_ids = None
                    try:
                        if "workface_id" in df.columns:
                            workface_ids = sorted({int(float(x)) for x in df["workface_id"].dropna().unique()})
                    except Exception:
                        workface_ids = None
                    try:
                        # å¢é‡è®­ç»ƒçª—å£ï¼šå¿…é¡»æŠŠâ€œéœ€è¦çš„åˆ—â€ä¼ ç»™DBå±‚ï¼Œç¡®ä¿çª—å£train_dfåˆ—é›†åˆä¸æ¨¡å‹å·²fitç‰¹å¾ä¸€è‡´
                        # ä¼˜å…ˆä½¿ç”¨å·²fitç‰¹å¾é¡ºåºï¼›è‹¥ä¸å­˜åœ¨åˆ™é€€å›å½“å‰é…ç½®çš„ training_features
                        needed_cols_for_window = None
                        try:
                            if getattr(self, "_fitted_feature_order", None):
                                needed_cols_for_window = list(self._fitted_feature_order)
                            else:
                                needed_cols_for_window = list(getattr(self, "training_features", []))
                        except Exception:
                            needed_cols_for_window = None
                        train_df = self.db.fetch_recent_training_window_with_features(
                            workface_ids=workface_ids,
                            max_date=max_date,
                            lookback_days=int(lookback_days),
                            limit=int(window_limit),
                            conn=db_conn,
                            needed_cols=needed_cols_for_window
                        )
                        if train_df is None or train_df.empty:
                            logger.warning("å¢é‡è®­ç»ƒçª—å£å–æ•°ä¸ºç©ºï¼Œå›é€€ä¸ºä»…æœ¬æ‰¹æ¬¡dfè®­ç»ƒ")
                            train_df = df
                        else:
                            logger.info(
                                f"å¢é‡è®­ç»ƒçª—å£å·²ç”Ÿæ•ˆï¼šlookback_days={lookback_days}ï¼Œwindow_limit={window_limit}ï¼Œ"
                                f"å®é™…è®­ç»ƒæ ·æœ¬={len(train_df)}ï¼ˆå«å½“å‰æ‰¹æ¬¡ï¼‰"
                            )
                    except Exception as _e:
                        logger.warning(f"å¢é‡è®­ç»ƒçª—å£æ‹‰å–å¤±è´¥ï¼ˆå›é€€ä¸ºä»…æœ¬æ‰¹æ¬¡dfè®­ç»ƒï¼‰ï¼š{repr(_e)}", exc_info=True)
                        train_df = df
                # è®­ç»ƒç›®æ ‡ y å¿…é¡»æ¥è‡ª train_dfï¼ˆå¦åˆ™çª—å£å³ä½¿æ‹¼äº†ä¹Ÿç­‰äºæ²¡ç”Ÿæ•ˆï¼‰
                y = self._smooth_training_targets(train_df, self.data_preprocessor.target_features, group_col="spatiotemporal_group")
                if (not do_full_train) and self.is_trained:
                    # --- å¢é‡è®­ç»ƒï¼šå¼ºåˆ¶ä½¿ç”¨å·²fitçš„ç‰¹å¾é¡ºåºä¸å·²fitçš„é¢„å¤„ç†å™¨ ---
                    if not getattr(self, "_fitted_feature_order", None):
                        logger.warning("å¢é‡è®­ç»ƒï¼šæœªæ‰¾åˆ°å·²fitç‰¹å¾é¡ºåºï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºå…¨é‡è®­ç»ƒ")
                        do_full_train = True
                        reason = "ç‰¹å¾é¡ºåºç¼ºå¤±è§¦å‘å…¨é‡è®­ç»ƒ"
                    if self.preprocessor is None:
                        logger.warning("å¢é‡è®­ç»ƒï¼šæœªæ‰¾åˆ°å·²fité¢„å¤„ç†å™¨ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºå…¨é‡è®­ç»ƒ")
                        do_full_train = True
                        reason = "é¢„å¤„ç†å™¨ç¼ºå¤±è§¦å‘å…¨é‡è®­ç»ƒ"

                if do_full_train:
                    # å…¨é‡è®­ç»ƒï¼šå…è®¸ä½¿ç”¨å½“å‰training_featureså¹¶é‡æ–°fité¢„å¤„ç†å™¨
                    X = train_df[self.training_features]
                    self._fitted_feature_order = X.columns.tolist()
                    logger.info(f"æ„å»ºè®­ç»ƒé›†: Xå½¢çŠ¶={X.shape}, yå½¢çŠ¶={y.shape}")
                    self.preprocessor, X_proc, _ = self.model_trainer.create_preprocessor(
                        X, self.data_preprocessor.base_categorical
                    )
                else:
                    # å¢é‡è®­ç»ƒï¼šå›ºå®šç‰¹å¾é›†åˆï¼Œç¼ºå¤±åˆ—è¡¥0ï¼Œé¿å…â€œè‡ªåŠ¨ç‰¹å¾é™çº§/æ¢å¤â€å¯¼è‡´ç»´åº¦å˜åŒ–
                    fitted_cols = list(self._fitted_feature_order)
                    missing = [c for c in fitted_cols if c not in train_df.columns]
                    if missing:
                        # è¿™é‡Œä¸ç›´æ¥æŠ¥é”™ï¼Œè€Œæ˜¯è¡¥0ï¼šå› ä¸ºæœ‰äº›å¢å¼ºç‰¹å¾åœ¨æ–°æ‰¹æ¬¡/å†å²çª—å£å¯èƒ½æš‚æ—¶ä¸å¯å¾—
                        logger.warning(f"å¢é‡è®­ç»ƒï¼šè®­ç»ƒé›†(df, å«çª—å£)ç¼ºå¤±{len(missing)}ä¸ªå·²fitç‰¹å¾ï¼Œå°†è¡¥0ï¼š{missing}")
                    X = train_df.reindex(columns=fitted_cols, fill_value=0)
                    logger.info(f"æ„å»ºè®­ç»ƒé›†(å¢é‡): Xå½¢çŠ¶={X.shape}, yå½¢çŠ¶={y.shape}")
                    # å…³é”®ï¼šåªtransformï¼Œä¸å†fitï¼Œç¡®ä¿è¾“å‡ºç»´åº¦æ’å®š
                    X_proc = self.preprocessor.transform(X)
                # Step 6: æ‰§è¡Œè®­ç»ƒ
                if do_full_train:
                    self.models = self.model_trainer._full_train(X_proc, y, self.data_preprocessor.target_features)
                else:
                    self.models = self.model_trainer._incremental_train(
                        X_proc, y, self.data_preprocessor.target_features, self.models
                    )
                # é˜²å¾¡ï¼šè®­ç»ƒå™¨è‹¥å¼‚å¸¸è¿”å›édictï¼ˆå†å²é—ç•™ï¼‰ï¼Œç«‹å³å¤±è´¥è§¦å‘å›æ»šï¼Œé¿å…â€œæ•°æ®æäº¤ä½†æ¨¡å‹å¼‚å¸¸â€
                if not isinstance(self.models, dict):
                    raise ValueError(f"è®­ç»ƒå¤±è´¥ï¼šmodelsç±»å‹å¼‚å¸¸({type(self.models).__name__})ï¼Œå°†è§¦å‘å›æ»š")

                # Step 8: æäº¤äº‹åŠ¡+æ›´æ–°çŠ¶æ€
                db_trans.commit()
                logger.info(f"äº‹åŠ¡æäº¤æˆåŠŸï¼Œ{saved_count} æ¡æ•°æ®å·²æŒä¹…åŒ–")
                # å…³é”®ä¿®å¤ï¼šäº‹åŠ¡å·²æäº¤ï¼Œåç»­å³ä½¿è¯„ä¼°å¤±è´¥ä¹Ÿä¸å…è®¸å†rollback
                db_trans = None
                self.total_samples = self.model_manager.get_total_samples_from_db(self.db)
                new_samples = self.total_samples - initial_samples
                self._print_step(f"æ ·æœ¬æ•°æ›´æ–°ï¼šæ–°å¢ {new_samples} æ¡ï¼Œç´¯è®¡ {self.total_samples} æ¡")
                # Step 9: å€™é€‰æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼ˆå‘å¸ƒé—¨æ§ï¼šä»…å½“è¯„ä¼°å¯ä¿¡(success)æ—¶æ‰è¦†ç›–çº¿ä¸Šæ¨¡å‹ï¼‰
                # è¯´æ˜ï¼šè®­ç»ƒä¸è¯„ä¼°è§£è€¦ã€‚å³ä½¿è¯„ä¼°æ— æ•ˆï¼Œæœ¬è½®æ ·æœ¬ä»å·²ç”¨äºè®­ç»ƒï¼›ä½†ä¸å…è®¸æŠŠâ€œæœªå¯ä¿¡è¯„ä¼°â€çš„æ¨¡å‹å‘å¸ƒä¸ºçº¿ä¸Šæ¨¡å‹ã€‚
                publish_ok = False
                publish_action = "skipped"  # published / kept_previous / skipped
                # Step 10: è®­ç»ƒåè¯„ä¼°ï¼ˆè¯„ä¼°å¤±è´¥åªé™çº§ï¼Œä¸å½±å“è®­ç»ƒæˆåŠŸï¼‰
                if len(df) <= 5:
                    eval_result = {
                        "status": "skipped",
                        "message": f"æ•°æ®é‡è¿‡å°‘({len(df)}æ¡)ï¼Œè·³è¿‡è¯„ä¼°é¿å…è¯¯åˆ¤",
                        "avg_rmse": None
                    }
                    agg_rmse = None
                    logger.info(f"å°æ•°æ®è®­ç»ƒ({len(df)}æ¡)ï¼šè·³è¿‡æ€§èƒ½è¯„ä¼°")
                else:
                    try:
                        eval_result = self.evaluate_model()
                        agg_rmse = eval_result.get("avg_rmse")
                    except Exception as _e:
                        # è¯„ä¼°å¤±è´¥ä¸åº”å¯¼è‡´è®­ç»ƒå¤±è´¥ï¼Œæ›´ä¸å…è®¸å›æ»šå·²æäº¤æ•°æ®
                        logger.error(f"è®­ç»ƒåè¯„ä¼°å¤±è´¥ï¼ˆå°†é™çº§ä¸ºwarningï¼Œä¸å½±å“è®­ç»ƒæäº¤ï¼‰ï¼š{repr(_e)}", exc_info=True)
                        eval_result = {"status": "warning", "message": f"è¯„ä¼°å¤±è´¥ï¼š{str(_e)}"}
                        agg_rmse = None
                # Step 11/12ï¼šæ€§èƒ½åŸºçº¿ + å›æ»šæ£€æŸ¥ï¼ˆä¿®æ­£ï¼šå…ˆæ£€æŸ¥å†æ›´æ–°åŸºçº¿ï¼Œä¸”åŸºçº¿åªåœ¨â€œå˜å¥½â€æ—¶æ›´æ–°ï¼‰
                baseline_old = self.baseline_rmse

                # 11.1 é¦–æ¬¡è®¾ç½®åŸºçº¿ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
                if agg_rmse is not None and baseline_old is None:
                    self.baseline_rmse = float(agg_rmse)
                    baseline_old = self.baseline_rmse
                    logger.info(f"è®¾ç½®åˆå§‹æ€§èƒ½åŸºçº¿: {self.baseline_rmse:.4f}")
                # 11.1 æ€§èƒ½å›æ»šæ£€æŸ¥ï¼šå¿…é¡»æ˜¯â€œå¯ä¿¡è¯„ä¼°â€æ‰å…è®¸è§¦å‘
                eval_code = (eval_result or {}).get("code", None)
                eval_ok = (eval_result or {}).get("status") == "success"
                eval_trustworthy = eval_ok and (eval_code not in ["evaluation_invalid"])

                if (eval_trustworthy and
                        agg_rmse is not None and
                        baseline_old is not None and
                        len(df) > 10):

                    # é˜²æ­¢é™¤0
                    if float(baseline_old) > 0:
                        drop_ratio = (float(agg_rmse) - float(baseline_old)) / float(baseline_old)
                    else:
                        drop_ratio = 0.0

                    logger.info(f"=== æ€§èƒ½æ£€æŸ¥è¯Šæ–­ ===")
                    logger.info(f"è®­ç»ƒæ•°æ®: {len(df)}æ¡, å½“å‰RMSE: {float(agg_rmse):.4f}")
                    logger.info(f"åŸºçº¿RMSE: {float(baseline_old):.4f}, ä¸‹é™æ¯”ä¾‹: {drop_ratio:.2%}")
                    logger.info(f"é˜ˆå€¼: {self.model_evaluator.perf_drop_ratio * 2:.2%}")

                    if drop_ratio > self.model_evaluator.perf_drop_ratio * 2:
                        logger.warning(f"æ€§èƒ½ä¸‹é™è¿‡å¤šï¼ˆ{drop_ratio:.2%}ï¼‰ï¼Œå°è¯•å›æ»š")
                        rollback_res = self.rollback_model(backup_index=-2)
                        if rollback_res.get("success"):
                            self._load_model()
                            # å›æ»šåï¼šæ¢å¤åŸºçº¿åˆ°å›æ»šå‰ä¸€ç‰ˆçš„è¯„ä¼°ç»“æœï¼ˆè‹¥å¯ç”¨ï¼‰
                            try:
                                if self.eval_history and len(self.eval_history) > 1:
                                    self.baseline_rmse = float(self.eval_history[-2]["avg_rmse"])
                            except Exception:
                                pass
                            logger.info(f"å›æ»šæˆåŠŸï¼ŒåŸºçº¿RMSEæ¢å¤ä¸ºï¼š{self.baseline_rmse}")
                else:
                    skip_reason = []
                    if not eval_ok:
                        skip_reason.append("è¯„ä¼°å¤±è´¥/æœªæˆåŠŸ")
                    if eval_code == "evaluation_invalid":
                        skip_reason.append("è¯„ä¼°è¾“å…¥ä¸å¯ä¿¡(evaluation_invalid)")
                    if agg_rmse is None:
                        skip_reason.append("æ— RMSEæ•°æ®")
                    if baseline_old is None:
                        skip_reason.append("æ— åŸºçº¿æ•°æ®")
                    if len(df) <= 10:
                        skip_reason.append("å°æ•°æ®è®­ç»ƒ")
                    logger.info(f"è·³è¿‡æ€§èƒ½å›æ»šæ£€æŸ¥: {', '.join(skip_reason)}")

                # 11.2 åŸºçº¿æ›´æ–°ç­–ç•¥ï¼šä»…å½“â€œè¯„ä¼°å¯ä¿¡ + æ€§èƒ½å˜å¥½â€æ—¶æ›´æ–°ï¼ˆé¿å…è¢«æ— æ•ˆè¯„ä¼°æ±¡æŸ“åŸºçº¿ï¼‰
                try:
                    eval_code = (eval_result or {}).get("code", None)
                    eval_ok = (eval_result or {}).get("status") == "success"
                    eval_trustworthy = eval_ok and (eval_code not in ["evaluation_invalid"])

                    if eval_trustworthy and agg_rmse is not None and self.baseline_rmse is not None and len(df) >= 10:
                        if float(agg_rmse) < float(self.baseline_rmse):
                            self.baseline_rmse = float(agg_rmse)
                            logger.info(f"æ›´æ–°æ€§èƒ½åŸºçº¿(æ›´ä¼˜): {self.baseline_rmse:.4f}")
                        else:
                            logger.info(
                                f"ä¿æŒæ€§èƒ½åŸºçº¿ä¸å˜ï¼šbaseline={float(self.baseline_rmse):.4f} å½“å‰={float(agg_rmse):.4f}"
                            )
                    elif eval_code == "evaluation_invalid":
                        logger.warning("æœ¬æ¬¡è¯„ä¼°ä¸º evaluation_invalidï¼šè·³è¿‡åŸºçº¿æ›´æ–°ï¼ˆéœ€å…ˆä¿®å¤å¢å¼ºç‰¹å¾ç”Ÿæˆé—­ç¯ï¼‰")
                except Exception:
                    pass

                # Step 13: å¦‚æœæ˜¯å¤§æ•°æ®é‡åˆå§‹è®­ç»ƒï¼Œè®¾ç½®å›ºå®šè¯„ä¼°é›†
                if len(df) >= 100 and not hasattr(self, 'fixed_evaluation_set'):
                    logger.info("å¤§æ•°æ®é‡è®­ç»ƒï¼Œè®¾ç½®å›ºå®šè¯„ä¼°é›†")
                    self.set_fixed_evaluation_set(df, size=50)
                # Step 13.5: å‘å¸ƒé—¨æ§ï¼ˆé¦–ä¸ªå¯ä¿¡è¯„ä¼°å¯å‘å¸ƒ + åç»­æŒ‰é˜ˆå€¼é—¨æ§ï¼‰
                # ç›®æ ‡ï¼š
                # 1) è‹¥çº¿ä¸Šå°šæ— æ¨¡å‹ï¼šé¦–ä¸ª eval_success ç›´æ¥å‘å¸ƒï¼Œå»ºç«‹â€œç”Ÿäº§èµ·ç‚¹â€
                # 2) è‹¥å·²æœ‰çº¿ä¸Šæ¨¡å‹ï¼šé»˜è®¤è¦æ±‚ä¸åŠ£äº baselineï¼ˆæˆ–å…è®¸è½»å¾®åŠ£åŒ–ï¼‰ï¼Œå¦åˆ™ä¸å‘å¸ƒï¼Œä»…ä¿å­˜å€™é€‰
                publish_first_success = True
                publish_allow_degrade_pct = 0.0
                try:
                    publish_first_success = self.config.getboolean("ModelEval", "publish_first_success", fallback=True)
                except Exception:
                    publish_first_success = True
                try:
                    publish_allow_degrade_pct = float(self.config.get("ModelEval", "publish_allow_degrade_pct", fallback="0.0"))
                except Exception:
                    publish_allow_degrade_pct = 0.0

                # åˆ¤æ–­çº¿ä¸Šæ˜¯å¦å·²æœ‰å·²å‘å¸ƒæ¨¡å‹æ–‡ä»¶
                online_exists = False
                try:
                    # preprocessor ä¸ training_features æ˜¯æœ€å…³é”®çš„â€œçº¿ä¸Šæ¨¡å‹å­˜åœ¨â€æ ‡å¿—
                    if os.path.exists(getattr(self.model_manager, "preprocessor_path", "")) and \
                       os.path.exists(getattr(self.model_manager, "features_path", "")):
                        # è‡³å°‘å­˜åœ¨ä¸€ä¸ªç›®æ ‡æ¨¡å‹æ–‡ä»¶å³å¯è®¤ä¸ºçº¿ä¸Šæ¨¡å‹å­˜åœ¨
                        model_dir = getattr(self.model_manager, "model_dir", None)
                        if model_dir and os.path.isdir(model_dir):
                            for fn in os.listdir(model_dir):
                                if fn.startswith("model_"):
                                    online_exists = True
                                    break
                except Exception:
                    online_exists = False

                # å‘å¸ƒåˆ¤å®šï¼šå¿…é¡»â€œå¯ä¿¡è¯„ä¼°â€æ‰å…è®¸å‘å¸ƒï¼ˆé¿å… evaluation_invalid è¯¯å¯¼ï¼‰
                try:
                    publish_ok = bool(eval_trustworthy)
                except Exception:
                    publish_ok = False

                # ç»†åŒ–é—¨æ§ï¼šçº¿ä¸Šæ— æ¨¡å‹ â†’ é¦–æ¬¡ success ç›´æ¥å‘å¸ƒ
                if publish_ok and (not online_exists) and publish_first_success:
                    logger.info("çº¿ä¸Šå°šæ— å·²å‘å¸ƒæ¨¡å‹ï¼šé¦–ä¸ªå¯ä¿¡è¯„ä¼°æ¨¡å‹å°†ç›´æ¥å‘å¸ƒï¼ˆå»ºç«‹ç”Ÿäº§èµ·ç‚¹ï¼‰")
                elif publish_ok:
                    # çº¿ä¸Šå·²æœ‰æ¨¡å‹ï¼šé»˜è®¤è¦æ±‚ä¸åŠ£äº baselineï¼ˆå¯é…ç½®å…è®¸è½»å¾®åŠ£åŒ–ï¼‰
                    try:
                        if agg_rmse is None or baseline_old is None:
                            publish_ok = False
                        else:
                            # å…è®¸è½»å¾®åŠ£åŒ–ï¼ˆä¾‹å¦‚ 0.02 è¡¨ç¤ºå…è®¸æ¯”baselineå·®2%ä»å¯å‘å¸ƒï¼‰
                            thr = float(baseline_old) * (1.0 + max(0.0, float(publish_allow_degrade_pct)))
                            publish_ok = (float(agg_rmse) <= thr)
                    except Exception:
                        publish_ok = False

                # å‘å¸ƒåŠ¨ä½œï¼šå‘å¸ƒåˆ™è¦†ç›–çº¿ä¸Šå¹¶å¤‡ä»½ï¼›ä¸å‘å¸ƒåˆ™ä¿å­˜å€™é€‰å¹¶å›åŠ è½½çº¿ä¸Š
                try:
                    if publish_ok:
                        self.model_manager.save_model(
                            self.models, self.preprocessor, self.training_features, self.data_preprocessor.target_features
                        )
                        publish_action = "published"
                        logger.info(f"å‘å¸ƒæˆåŠŸï¼špublish_action={publish_action}")
                    else:
                        # ä¿å­˜å€™é€‰æ¨¡å‹ï¼ˆä¾¿äºæ’æŸ¥ä¸å¤ç°ï¼‰
                        try:
                            _tag = f"{reason}_{(eval_result or {}).get('status', 'none')}"
                            self.model_manager.save_candidate_model(
                                self.models, self.preprocessor, self.training_features,
                                self.data_preprocessor.target_features,
                                tag=_tag
                            )
                        except Exception as _se:
                            logger.warning(f"å€™é€‰æ¨¡å‹ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“è®­ç»ƒæäº¤ï¼‰ï¼š{repr(_se)}")

                        # ä¸å‘å¸ƒï¼šçº¿ä¸Šç»§ç»­ä½¿ç”¨ä¸Šä¸€ç‰ˆï¼›ä¸ºå®‰å…¨èµ·è§å›åŠ è½½çº¿ä¸Šæ¨¡å‹åˆ°å†…å­˜
                        if online_exists:
                            try:
                                self._load_model()
                            except Exception as _le:
                                logger.warning(f"æ¢å¤çº¿ä¸Šæ¨¡å‹å¤±è´¥ï¼š{repr(_le)}", exc_info=True)
                            publish_action = "kept_previous"
                        else:
                            # çº¿ä¸Šæœ¬å°±æ²¡æœ‰æ¨¡å‹ï¼Œä¸”æœ¬è½®ä¸æ»¡è¶³å‘å¸ƒæ¡ä»¶
                            publish_action = "skipped"

                        logger.info(f"æœ¬è½®ä¸å‘å¸ƒï¼špublish_action={publish_action}")
                except Exception as _pe:
                    logger.warning(f"å‘å¸ƒæµç¨‹å¼‚å¸¸ï¼ˆé™çº§ä¸ºä¸å‘å¸ƒå¹¶ä¿ç•™çº¿ä¸Šï¼‰ï¼š{repr(_pe)}", exc_info=True)
                    publish_action = "kept_previous" if online_exists else "skipped"
                # Step 12: è®°å½•è®­ç»ƒå†å²åˆ°æ•°æ®åº“
                train_duration = (datetime.now() - train_start).total_seconds()
                # ç›‘æ§è°ƒç”¨
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode=reason,  # ä»åŸæœ‰å˜é‡è·å–
                    sample_count=len(df),  # ä»åŸæœ‰å˜é‡è·å–
                    duration=train_duration,
                    rmse=agg_rmse  # ä»åŸæœ‰å˜é‡è·å–
                )
                eval_status = str(eval_result.get("status")) if isinstance(eval_result, dict) else "none"
                published_flag = (publish_action == "published")
                record_status = "success" if published_flag else "partial_success"
                rmse_str = f"{float(agg_rmse):.4f}" if agg_rmse is not None else "æœªè®¡ç®—"
                # å°½é‡æŠŠâ€œè¯„ä¼°æ— æ•ˆåŸå› â€è½åº“ï¼Œä¾¿äºå‰ç«¯/è¿ç»´å®šä½
                invalid_reason = ""
                try:
                    if isinstance(eval_result, dict) and eval_result.get("status") != "success":
                        invalid_reason = str(eval_result.get("message") or "")
                except Exception:
                    invalid_reason = ""
                training_record = {
                    "sample_count": len(df),
                    "total_samples": self.total_samples,
                    "train_mode": reason,
                    "status": record_status,
                    "message": f"è®­ç»ƒå®Œæˆï¼ˆ{reason}ï¼‰ï¼ŒRMSEï¼š{rmse_str}ï¼Œeval={eval_status}ï¼Œpublish={publish_action}"
                    +(f"ï¼ŒåŸå› ï¼š{invalid_reason}" if invalid_reason else ""),
                    "duration": train_duration,
                    "train_time": datetime.now()
                }
                record_id = self.db.insert_training_record(training_record)

                # ===== P0ï¼šç»Ÿä¸€å¯¹å¤–è¯­ä¹‰ï¼ˆsuccess / partial_success / warningï¼‰=====
                warnings = []
                eval_status = (eval_result or {}).get("status", None)
                eval_code = (eval_result or {}).get("code", None)

                final_status = "success"
                final_message = f"è®­ç»ƒå®Œæˆï¼ˆæ¨¡å¼ï¼š{reason}ï¼‰"

                # è¯„ä¼°è¾“å…¥ä¸å¯ä¿¡ï¼šè®­ç»ƒå¯æˆåŠŸï¼Œä½†å¿…é¡»æç¤ºå‰ç«¯â€œæŒ‡æ ‡ä¸å¯ç”¨/éœ€æ•´æ”¹â€
                if eval_status == "warning" and eval_code == "evaluation_invalid":
                    final_status = "partial_success"
                    warn_msg = (eval_result or {}).get("message", "è¯„ä¼°è¾“å…¥ä¸å¯ä¿¡ï¼ševaluation_invalid")
                    warnings.append(warn_msg)
                    final_message = f"è®­ç»ƒå®Œæˆï¼Œä½†è¯„ä¼°æ— æ•ˆï¼ˆ{eval_code}ï¼‰"

                training_result = {
                    "status": record_status,
                    "message": f"è®­ç»ƒå®Œæˆï¼ˆ{reason}ï¼‰ï¼ŒRMSEï¼š{rmse_str}ï¼Œeval={eval_status}ï¼Œpublish={publish_action}"
                    +(f"ï¼ŒåŸå› ï¼š{invalid_reason}" if invalid_reason else ""),
                    "warnings": warnings,  # ç»™å‰ç«¯å±•ç¤ºç”¨
                    "training_stats": {
                        "processed_samples": len(df),
                        "saved_to_db": saved_count,
                        "new_samples": new_samples,
                        "total_samples": self.total_samples,
                        "training_mode": reason,
                        "evaluation_rmse": agg_rmse,
                        "training_duration": round(train_duration, 2),
                        "record_id": record_id
                    },
                    # success æ—¶ï¼šè¿”å›å®Œæ•´è¯„ä¼°ï¼›evaluation_invalid æ—¶ï¼šä¹Ÿè¿”å›ï¼ˆè®©å‰ç«¯çœ‹åˆ°åŸå› ä¸å»ºè®®ï¼‰
                    "evaluation_details": eval_result if (
                                eval_result and eval_status in ["success", "warning"]) else None
                }

                rmse_str = f"{agg_rmse:.4f}" if agg_rmse is not None else "æ— è¯„ä¼°æ•°æ®"
                logger.info(f"è®­ç»ƒåè¯„ä¼°RMSE: {rmse_str}")
                # ============ åªåœ¨è®­ç»ƒæˆåŠŸå®Œæˆåæ·»åŠ è¯Šæ–­ä¿¡æ¯è¾“å‡º ============
                if training_result.get("status") == "success":
                    # è¾“å‡ºè®­ç»ƒè¯Šæ–­ä¿¡æ¯
                    self._print_training_diagnosis()

                return training_result

            except Exception as e:
                # è®­ç»ƒå¤±è´¥ â†’ å›æ»šäº‹åŠ¡
                # å…³é”®ï¼šstr(e) å¯èƒ½è¢«å¤–å±‚ KeyError ç­‰è¦†ç›–ï¼Œå¢åŠ  repr(e) ä¾¿äºå®šä½çœŸå®æ ¹å› 
                logger.error(f"è®­ç»ƒå¤±è´¥ï¼Œè§¦å‘å›æ»šï¼ˆstrï¼‰ï¼š{str(e)}", exc_info=True)
                logger.error(f"è®­ç»ƒå¤±è´¥ï¼Œè§¦å‘å›æ»šï¼ˆreprï¼‰ï¼š{repr(e)}", exc_info=True)
                # è®­ç»ƒå¤±è´¥æ—¶ä¹Ÿè®°å½•ç›‘æ§
                train_duration = (datetime.now() - train_start).total_seconds()
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="failed",
                    sample_count=len(df) if 'df' in locals() else 0,
                    duration=train_duration,
                    rmse=None
                )
                if db_trans:
                    try:
                        db_trans.rollback()
                        logger.info("äº‹åŠ¡å·²å›æ»šï¼Œæ— æ®‹ç•™æ•°æ®")
                    except Exception as rollback_e:
                        if custom_create_time and db_conn:
                            from sqlalchemy import text
                            delete_sql = text("DELETE FROM t_prediction_parameters WHERE create_time = :ct")
                            db_conn.execute(delete_sql, {"ct": custom_create_time})
                            db_trans.commit()
                            logger.info(f"æ‰‹åŠ¨åˆ é™¤æ®‹ç•™æ•°æ®ï¼ˆcreate_timeï¼š{custom_create_time}ï¼‰")
                return {
                    "status": "error",
                    # è¿”å› message åŒæ—¶å¸¦ä¸Š repr(e)ï¼Œé¿å…åªçœ‹åˆ° "'pred_id'" è¿™ç§è¢«è¦†ç›–çš„ä¿¡æ¯
                    "message": f"{str(e)} | {repr(e)}",
                    "training_stats": {
                        "processed_samples": len(df) if 'df' in locals() else 0,
                        "saved_to_db": saved_count,
                        "data_rolled_back": True
                    }
                }
            finally:
                if db_conn:
                    try:
                        db_conn.close()
                        logger.debug("è®­ç»ƒæµç¨‹æ•°æ®åº“è¿æ¥å·²å…³é—­")
                    except Exception as close_e:
                        logger.warning(f"å…³é—­è¿æ¥å¤±è´¥ï¼š{str(close_e)}")

    def evaluate_model(self, eval_size=200, eval_df=None, use_fixed_set=False):
        """
        å¢å¼ºçš„æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œæ”¯æŒå›ºå®šè¯„ä¼°é›†

        :param eval_size: è¯„ä¼°æ ·æœ¬æ•°
        :param eval_df: å¤–éƒ¨è¯„ä¼°æ•°æ®
        :param use_fixed_set: æ˜¯å¦ä½¿ç”¨å›ºå®šè¯„ä¼°é›†
        :return: è¯„ä¼°ç»“æœ
        """
        if use_fixed_set and hasattr(self, 'fixed_evaluation_set') and self.fixed_evaluation_set is not None:
            logger.info("ä½¿ç”¨å›ºå®šè¯„ä¼°é›†è¿›è¡Œè¯„ä¼°")
            eval_df = self.fixed_evaluation_set

        return self.model_evaluator.evaluate_model(
            self.models, self.preprocessor, self.training_features, self.data_preprocessor.target_features,
            self._fitted_feature_order, self.db, eval_size, eval_df,
            data_preprocessor=self.data_preprocessor
        )

    def predict(self, data):
        """æ¨¡å‹é¢„æµ‹ï¼ˆå§”æ‰˜ç»™ModelPredictorï¼‰"""
        return self.model_predictor.predict(
            data, self.models, self.preprocessor, self.training_features,
            self.data_preprocessor.target_features, self._fitted_feature_order, self.is_trained,
            self.file_lock, self.data_preprocessor, self.fault_calculator, self.db
        )

    def retrain_from_db(self, workface_id=None, limit=None):
        """ä»æ•°æ®åº“é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰"""
        self._print_header("ä»æ•°æ®åº“é‡æ–°è®­ç»ƒæ¨¡å‹")

        # è®°å½•å‘åå…¼å®¹çš„è­¦å‘Š
        logger.warning("retrain_from_dbæ–¹æ³•å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨retrain_from_db_fullæ–¹æ³•")

        try:
            # ä»æ•°æ®åº“è¯»å–å†å²æ•°æ®
            df = self.model_manager.get_recent_data_from_db(self.db, limit=limit)
            if df.empty:
                msg = "æœªä»æ•°æ®åº“è¯»å–åˆ°ä»»ä½•æ•°æ®ï¼Œæ— æ³•é‡æ–°è®­ç»ƒ"
                logger.warning(msg)
                self._print_result(msg)
                return {"status": "warning", "message": msg}

            # ç­›é€‰ç‰¹å®šå·¥ä½œé¢æ•°æ®
            if workface_id is not None and 'workface_id' in df.columns:
                df = df[df["workface_id"] == workface_id].reset_index(drop=True)
                self._print_step(f"ç­›é€‰å·¥ä½œé¢ID={workface_id}ï¼Œå‰©ä½™æ ·æœ¬æ•°ï¼š{len(df)}")
                if df.empty:
                    msg = f"å·¥ä½œé¢ID={workface_id} æ— æ•°æ®"
                    logger.warning(msg)
                    return {"status": "warning", "message": msg}

            # é‡æ–°è®¡ç®—æ–­å±‚ç³»æ•°
            logger.info("é‡æ–°è®­ç»ƒï¼šè‡ªåŠ¨è®¡ç®—æ–­å±‚å½±å“ç³»æ•°")
            df = self.calculate_fault_influence_strength(df)

            # æ‰§è¡Œè®­ç»ƒï¼ˆä½¿ç”¨æ–°çš„å…¨é‡é‡æ–°è®­ç»ƒæ–¹æ³•ï¼‰
            result = self.retrain_from_db_full(
                workface_id=workface_id,
                sample_limit=limit,
                force_full_train=True
            )
            return result
        except Exception as e:
            logger.error(f"é‡æ–°è®­ç»ƒå¤±è´¥ï¼š{str(e)}", exc_info=True)
            return {"status": "error", "message": str(e)}

    def rollback_model(self, backup_index=-1):
        """æ¨¡å‹å›æ»šï¼ˆå§”æ‰˜ç»™ModelManagerï¼‰"""
        result = self.model_manager.rollback_model(backup_index, self.data_preprocessor.target_features)
        if result["success"]:
            # é‡æ–°åŠ è½½æ¨¡å‹
            self._load_model()
            # åŒæ­¥çŠ¶æ€åˆ°é¢„å¤„ç†å™¨
            self.data_preprocessor.is_trained = self.is_trained
            self.data_preprocessor.training_features = self.training_features
        return result

    def get_model_status(self):
        """è·å–æ¨¡å‹å½“å‰çŠ¶æ€"""
        backup_count = 0
        backup_root = os.path.join(self.model_dir, "backup")
        if os.path.exists(backup_root):
            try:
                backup_count = len(os.listdir(backup_root))
            except Exception:
                backup_count = 0

        latest_eval = self.eval_history[-1] if self.eval_history else None

        return {
            "is_trained": self.is_trained,
            "total_samples": self.total_samples,
            "training_features_count": len(self.training_features) if self.training_features else 0,
            "target_features": self.data_preprocessor.target_features,
            "backup_count": backup_count,
            "latest_evaluation": latest_eval,
            "last_train_time": self.training_stats[-1]["timestamp"] if self.training_stats else None
        }

    def _save_training_stats(self, train_mode, sample_count, agg_rmse):
        """ä¿å­˜è®­ç»ƒç»Ÿè®¡åˆ°å†…å­˜"""
        if not hasattr(self, 'training_stats'):
            self.training_stats = []
        self.training_stats.append({
            "timestamp": datetime.now(),
            "train_mode": train_mode,
            "sample_count": sample_count,
            "total_samples": self.total_samples,
            "agg_rmse": agg_rmse
        })
        self.training_stats = self.training_stats[-100:]
        logger.debug(f"è®­ç»ƒç»Ÿè®¡æ›´æ–°ï¼Œç´¯è®¡ {len(self.training_stats)} æ¡è®°å½•")

    def create_fixed_evaluation_set(self, data, size=50):
        """
        åˆ›å»ºå›ºå®šçš„è¯„ä¼°æ•°æ®é›†
        ç¡®ä¿ä¸åŒè®­ç»ƒé˜¶æ®µä½¿ç”¨ç›¸åŒçš„è¯„ä¼°åŸºå‡†

        :param data: è®­ç»ƒæ•°æ®
        :param size: è¯„ä¼°é›†å¤§å°
        :return: å›ºå®šè¯„ä¼°æ•°æ®é›†
        """
        try:
            if isinstance(data, list):
                df = pd.DataFrame(data)
            else:
                df = data.copy()

            # ç¡®ä¿æ•°æ®é‡è¶³å¤Ÿ
            if len(df) < size:
                logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}æ¡)ï¼Œæ— æ³•åˆ›å»º{size}æ¡çš„å›ºå®šè¯„ä¼°é›†")
                return df

            # æŒ‰å·¥ä½œé¢åˆ†å±‚é‡‡æ ·ï¼Œç¡®ä¿è¯„ä¼°é›†ä»£è¡¨æ€§
            fixed_eval_set = []
            if 'workface_id' in df.columns:
                workface_groups = df.groupby('workface_id')
                for workface_id, group in workface_groups:
                    group_size = max(1, int(size * len(group) / len(df)))
                    if len(group) >= group_size:
                        sampled = group.sample(n=group_size, random_state=42)
                        fixed_eval_set.append(sampled)

                if fixed_eval_set:
                    fixed_eval_df = pd.concat(fixed_eval_set, ignore_index=True)
                    # å¦‚æœæ€»æ•°è¶…è¿‡sizeï¼Œéšæœºé‡‡æ ·è°ƒæ•´
                    if len(fixed_eval_df) > size:
                        fixed_eval_df = fixed_eval_df.sample(n=size, random_state=42)
                else:
                    fixed_eval_df = df.sample(n=size, random_state=42)
            else:
                fixed_eval_df = df.sample(n=size, random_state=42)

            logger.info(f"åˆ›å»ºå›ºå®šè¯„ä¼°é›†: {len(fixed_eval_df)}æ¡æ•°æ®")
            return fixed_eval_df

        except Exception as e:
            logger.error(f"åˆ›å»ºå›ºå®šè¯„ä¼°é›†å¤±è´¥: {str(e)}")
            # å¤±è´¥æ—¶å›é€€åˆ°éšæœºé‡‡æ ·
            return df.sample(n=min(size, len(df)), random_state=42)

    def set_fixed_evaluation_set(self, data, size=50):
        """
        è®¾ç½®å›ºå®šè¯„ä¼°æ•°æ®é›†ä¾›åç»­ä½¿ç”¨
        """
        self.fixed_evaluation_set = self.create_fixed_evaluation_set(data, size)
        logger.info(f"å›ºå®šè¯„ä¼°é›†å·²è®¾ç½®: {len(self.fixed_evaluation_set)}æ¡æ•°æ®")
        return self.fixed_evaluation_set

    def retrain_from_db_full(self, workface_id=None, sample_limit=None, force_full_train=True):
        """
        å…¨é‡é‡æ–°è®­ç»ƒæ–¹æ³•ï¼ˆé˜²æ­¢æ¨¡å‹è¢«è¯¯åˆ é™¤ï¼Œå¼ºåˆ¶å…¨é‡è®­ç»ƒï¼‰

        :param workface_id: intï¼Œå¯é€‰ï¼Œç­›é€‰ç‰¹å®šå·¥ä½œé¢æ•°æ®
        :param sample_limit: intï¼Œå¯é€‰ï¼Œé™åˆ¶è®­ç»ƒæ ·æœ¬æ•°ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
        :param force_full_train: boolï¼Œæ˜¯å¦å¼ºåˆ¶å…¨é‡è®­ç»ƒï¼ˆé»˜è®¤Trueï¼‰
        :return: dictï¼Œè®­ç»ƒç»“æœ
        """
        with self.file_lock:
            self._print_header("å…¨é‡é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆä»æ•°æ®åº“æ¢å¤ï¼‰")
            retrain_start = datetime.now()

            try:
                # Step 1: ä»æ•°æ®åº“è¯»å–å†å²æ•°æ®ï¼ˆä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ï¼‰
                logger.info(f"ä»æ•°æ®åº“è¯»å–å†å²æ•°æ®ï¼šå·¥ä½œé¢å¯¹{workface_id}ï¼Œæ ·æœ¬é™åˆ¶{sample_limit}")
                df = self.model_manager.get_recent_data_from_db(self.db, limit=sample_limit)

                if df.empty:
                    msg = "æœªä»æ•°æ®åº“è¯»å–åˆ°ä»»ä½•æ•°æ®ï¼Œæ— æ³•é‡æ–°è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": 0, "training_performed": False}
                    }

                # Step 2: ç­›é€‰ç‰¹å®šå·¥ä½œé¢æ•°æ®
                if workface_id is not None and 'workface_id' in df.columns:
                    original_count = len(df)
                    df = df[df["workface_id"] == workface_id].reset_index(drop=True)
                    if df.empty:
                        msg = f"å·¥ä½œé¢ID={workface_id} æ— æ•°æ®"
                        logger.warning(msg)
                        return {"status": "warning", "message": msg}
                    logger.info(f"ç­›é€‰å·¥ä½œé¢ID={workface_id}ï¼Œæ ·æœ¬æ•°ï¼š{original_count} â†’ {len(df)}")

                # Step 3: æ•°æ®é¢„å¤„ç†ï¼ˆé‡æ–°è®¡ç®—æ–­å±‚å½±å“ç³»æ•°ï¼‰
                logger.info("å…¨é‡é‡æ–°è®­ç»ƒï¼šè‡ªåŠ¨è®¡ç®—æ–­å±‚å½±å“ç³»æ•°")
                try:
                    df = self.calculate_fault_influence_strength(df)
                except Exception as e:
                    logger.error(f"è®¡ç®—æ–­å±‚å½±å“ç³»æ•°å¤±è´¥ï¼š{str(e)}ï¼Œä½¿ç”¨ç°æœ‰å€¼")
                    # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œä½¿ç”¨ç°æœ‰å€¼

                # Step 4: æ•°æ®é¢„å¤„ç†ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰
                try:
                    df_processed, training_features = self.data_preprocessor.preprocess_data(
                        df, is_training=True, fault_calculator=self.fault_calculator, db_utils=self.db
                    )
                except Exception as e:
                    logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
                    raise ValueError(f"æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")

                # Step 5: æ£€æŸ¥æœ€å°æ ·æœ¬æ•°
                if len(df_processed) < self.min_train_samples:
                    msg = f"æ ·æœ¬æ•° {len(df_processed)} < æœ€å°è®­ç»ƒæ ·æœ¬æ•° {self.min_train_samples}ï¼Œæ— æ³•é‡æ–°è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": len(df_processed), "training_performed": False}
                    }

                # Step 6: å¼ºåˆ¶é…ç½®ä¸ºå…¨é‡è®­ç»ƒæ¨¡å¼
                logger.info("å¼ºåˆ¶ä½¿ç”¨å…¨é‡è®­ç»ƒé…ç½®")
                # åˆ‡æ¢åˆ°å…¨é‡è®­ç»ƒé…ç½®ï¼ˆphase1ï¼‰
                config_before = self.current_config
                if self.current_config != "config_phase1.ini":
                    logger.info(f"åˆ‡æ¢åˆ°å…¨é‡è®­ç»ƒé…ç½®ï¼š{config_before} â†’ config_phase1.ini")
                    self.reload_config("config_phase1.ini", reload_database=False)

                # Step 7: æ„å»ºè®­ç»ƒé›†
                X = df_processed[training_features]
                y = df_processed[self.data_preprocessor.target_features].values
                fitted_feature_order = X.columns.tolist()

                # Step 8: ç‰¹å¾é¢„å¤„ç†
                preprocessor, X_proc, _ = self.model_trainer.create_preprocessor(
                    X, self.data_preprocessor.base_categorical
                )

                # Step 9: æ‰§è¡Œå…¨é‡è®­ç»ƒï¼ˆå¼ºåˆ¶ä½¿ç”¨å…¨é‡è®­ç»ƒé€»è¾‘ï¼‰
                logger.info(
                    f"å¼€å§‹å…¨é‡è®­ç»ƒï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼Œç›®æ ‡æ•°ï¼š{len(self.data_preprocessor.target_features)}")
                models = self.model_trainer._full_train(X_proc, y, self.data_preprocessor.target_features)

                # Step 10: æ›´æ–°æ¨¡å‹çŠ¶æ€
                self.models = models
                self.preprocessor = preprocessor
                self.training_features = training_features
                self._fitted_feature_order = fitted_feature_order
                self.is_trained = True
                self.data_preprocessor.is_trained = True
                self.data_preprocessor.training_features = training_features
                # Step 10.5ï¼ˆä¿®æ­£ï¼‰ï¼šå…ˆä¿å­˜å€™é€‰ï¼Œå†è¯„ä¼°ï¼Œæœ€åå†³å®šæ˜¯å¦å‘å¸ƒ
                publish_action = "skipped"

                # Step 11: ä¿å­˜å€™é€‰æ¨¡å‹ï¼ˆä¸è¦†ç›–çº¿ä¸Šï¼‰
                try:
                    _tag = f"retrain_{str(datetime.now().date())}"
                    self.model_manager.save_candidate_model(
                        self.models, self.preprocessor, self.training_features,
                        self.data_preprocessor.target_features, tag=_tag
                    )
                except Exception as _se:
                    logger.warning(f"å€™é€‰æ¨¡å‹ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“è®­ç»ƒæäº¤ï¼‰ï¼š{repr(_se)}")

                # Step 12: æ¨¡å‹è¯„ä¼°
                eval_result = None
                if len(df_processed) > 5:  # é¿å…å°æ•°æ®è¯„ä¼°ä¸å‡†ç¡®
                    try:
                        eval_result = self.evaluate_model(eval_size=min(50, len(df_processed)), eval_df=df_processed)
                        logger.info(
                            f"é‡æ–°è®­ç»ƒåè¯„ä¼°ç»“æœï¼šçŠ¶æ€={eval_result.get('status')}, RMSE={eval_result.get('avg_rmse')}")
                    except Exception as e:
                        logger.warning(f"é‡æ–°è®­ç»ƒåè¯„ä¼°å¤±è´¥ï¼š{str(e)}")
                # Step 12.5: è¯„ä¼°åå‘å¸ƒé—¨æ§ï¼ˆä¸ä¸»è®­ç»ƒä¸€è‡´ï¼‰
                import os
                publish_first_success = True
                publish_allow_degrade_pct = 0.0
                try:
                    publish_first_success = self.config.getboolean("ModelEval", "publish_first_success", fallback=True)
                except Exception:
                    publish_first_success = True
                try:
                    publish_allow_degrade_pct = float(self.config.get("ModelEval", "publish_allow_degrade_pct", fallback="0.0"))
                except Exception:
                    publish_allow_degrade_pct = 0.0

                online_exists = False
                try:
                    if os.path.exists(getattr(self.model_manager, "preprocessor_path", "")) and \
                       os.path.exists(getattr(self.model_manager, "features_path", "")):
                        model_dir = getattr(self.model_manager, "model_dir", None)
                        if model_dir and os.path.isdir(model_dir):
                            for fn in os.listdir(model_dir):
                                if fn.startswith("model_"):
                                    online_exists = True
                                    break
                except Exception:
                    online_exists = False

                ev_ok = False
                ev_code = None
                agg_rmse = None
                try:
                    if isinstance(eval_result, dict):
                        ev_ok = (str(eval_result.get("status", "")).lower() == "success")
                        ev_code = eval_result.get("code", None)
                        agg_rmse = eval_result.get("avg_rmse", None)
                except Exception:
                    ev_ok = False
                eval_trustworthy = bool(ev_ok and (ev_code not in ["evaluation_invalid"]))

                publish_ok = bool(eval_trustworthy)
                if publish_ok and (not online_exists) and publish_first_success:
                    logger.info("çº¿ä¸Šå°šæ— å·²å‘å¸ƒæ¨¡å‹ï¼šretrain çš„é¦–ä¸ªå¯ä¿¡è¯„ä¼°æ¨¡å‹å°†ç›´æ¥å‘å¸ƒ")
                elif publish_ok:
                    # çº¿ä¸Šå·²æœ‰æ¨¡å‹ï¼šé»˜è®¤è¦æ±‚ä¸åŠ£äº baselineï¼ˆå…è®¸è½»å¾®åŠ£åŒ–ï¼‰
                    baseline_old = getattr(self, "baseline_rmse", None)
                    try:
                        if agg_rmse is None or baseline_old is None:
                            publish_ok = False
                        else:
                            thr = float(baseline_old) * (1.0 + max(0.0, float(publish_allow_degrade_pct)))
                            publish_ok = (float(agg_rmse) <= thr)
                    except Exception:
                        publish_ok = False

                if publish_ok:
                    try:
                        self.model_manager.save_model(
                            self.models, self.preprocessor, self.training_features, self.data_preprocessor.target_features
                        )
                        publish_action = "published"
                        logger.info("retrain å‘å¸ƒæˆåŠŸï¼šçº¿ä¸Šæ¨¡å‹å·²æ›´æ–°")
                    except Exception as _pe:
                        logger.warning(f"retrain å‘å¸ƒå¤±è´¥ï¼ˆé™çº§ä¸ºä¸å‘å¸ƒï¼‰ï¼š{repr(_pe)}", exc_info=True)
                        publish_ok = False

                if not publish_ok:
                    # ä¸å‘å¸ƒï¼šå›åŠ è½½çº¿ä¸Šæ¨¡å‹ï¼Œé¿å…æœåŠ¡è¯¯ç”¨å€™é€‰
                    if online_exists:
                        try:
                            self._load_model()
                        except Exception as _le:
                            logger.warning(f"æ¢å¤çº¿ä¸Šæ¨¡å‹å¤±è´¥ï¼š{repr(_le)}", exc_info=True)
                        publish_action = "kept_previous"
                    else:
                        publish_action = "skipped"

                # Step 13: æ¢å¤åŸé…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if config_before != "config_phase1.ini":
                    logger.info(f"æ¢å¤åŸé…ç½®ï¼šconfig_phase1.ini â†’ {config_before}")
                    self.reload_config(config_before, reload_database=False)

                # Step 14: è®¡ç®—è®­ç»ƒè€—æ—¶
                train_duration = (datetime.now() - retrain_start).total_seconds()

                # Step 15: è®°å½•ç›‘æ§
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="full_retrain",  # ç‰¹æ®Šæ ‡è®°ä¸ºå…¨é‡é‡æ–°è®­ç»ƒ
                    sample_count=len(df_processed),
                    duration=train_duration,
                    rmse=eval_result.get("avg_rmse") if eval_result else None
                )

                # Step 16: è®°å½•è®­ç»ƒå†å²
                training_record = {
                    "sample_count": len(df_processed),
                    "total_samples": self.total_samples,  # æ³¨æ„ï¼šä¸æ›´æ–°æ€»æ ·æœ¬æ•°
                    "train_mode": "full_retrain",
                    "status": "success",
                    "message": f"å…¨é‡é‡æ–°è®­ç»ƒå®Œæˆï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼ŒRMSEï¼š{eval_result.get('avg_rmse') if eval_result else 'æœªè¯„ä¼°'}",
                    "duration": train_duration,
                    "train_time": datetime.now()
                }
                record_id = self.db.insert_training_record(training_record)

                # Step 17: æ„å»ºè¿”å›ç»“æœ
                training_result = {
                    "status": "success",
                    "message": f"å…¨é‡é‡æ–°è®­ç»ƒå®Œæˆï¼ˆæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼‰",
                    "training_stats": {
                        "processed_samples": len(df_processed),
                        "training_mode": "full_retrain",
                        "evaluation_rmse": eval_result.get("avg_rmse") if eval_result else None,
                        "training_duration": round(train_duration, 2),
                        "record_id": record_id,
                        "workface_filtered": workface_id is not None,
                        "sample_limit_applied": sample_limit is not None
                    },
                    "evaluation_details": eval_result if eval_result and eval_result.get(
                        "status") == "success" else None
                }

                # è¾“å‡ºè®­ç»ƒè¯Šæ–­ä¿¡æ¯
                if training_result.get("status") == "success":
                    self._print_training_diagnosis()

                logger.info(f"å…¨é‡é‡æ–°è®­ç»ƒæˆåŠŸå®Œæˆï¼Œè€—æ—¶ï¼š{train_duration:.2f}ç§’ï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}")
                return training_result

            except Exception as e:
                # è®­ç»ƒå¤±è´¥å¤„ç†
                train_duration = (datetime.now() - retrain_start).total_seconds()
                logger.error(f"å…¨é‡é‡æ–°è®­ç»ƒå¤±è´¥ï¼š{str(e)}", exc_info=True)

                # è®°å½•ç›‘æ§
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="full_retrain_failed",
                    sample_count=len(df) if 'df' in locals() else 0,
                    duration=train_duration,
                    rmse=None
                )

                return {
                    "status": "error",
                    "message": str(e),
                    "training_stats": {
                        "processed_samples": len(df) if 'df' in locals() else 0,
                        "training_duration": round(train_duration, 2),
                        "training_performed": False
                    }
                }


    def log_training_brief(mode, n_samples, perf, baseline, metrics, feature_stats):
        """
        ä»…ç”¨äºæ§åˆ¶å°çš„æç®€è¾“å‡º
        """
        brief_logger = logger.bind(brief=True)

        brief_logger.info(f"[TRAIN] mode={mode}, samples={n_samples}")
        delta = (baseline - perf) / baseline * 100 if baseline else 0
        brief_logger.info(f"[PERF ] RMSE={perf:.4f}  baseline={baseline:.4f}  Î”={delta:.2f}%")

        for tgt, m in (metrics or {}).items():
            try:
                rmse = float(m.get("rmse", 0.0))
                r2 = float(m.get("r2", 0.0))
            except Exception:
                rmse, r2 = 0.0, 0.0
            brief_logger.info(f"[TGT  ] {tgt:<12}: RMSE={rmse:.4f} RÂ²={r2:.4f}")

        # feature_stats å…œåº•ï¼Œé¿å… KeyError
        hs = (feature_stats or {}).get("historical", "NA")
        ts = (feature_stats or {}).get("trend", "NA")
        ar = (feature_stats or {}).get("advance_rate", "NA")
        brief_logger.info(f"[STAT ] hist_mean:{hs}  trend:{ts}  advance_rate:{ar}")
