"""
ç…¤çŸ¿ç“¦æ–¯é£é™©é¢„æµ‹ç³»ç»Ÿ - ä¸»æ¨¡å‹ç±»
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„æ¨¡å‹æ¥å£
"""
import os
from datetime import datetime

import pandas as pd
from filelock import FileLock
from loguru import logger
import configparser
# å¯¼å…¥å„åŠŸèƒ½æ¨¡å—
from config_utils import ConfigUtils
from fault_calculator import FaultCalculator
from regional_measure_calculator import RegionalMeasureCalculator
from data_preprocessor import DataPreprocessor
from model_trainer import ModelTrainer
from model_evaluator import ModelEvaluator
from model_predictor import ModelPredictor
from model_manager import ModelManager
from db_utils import DBUtils
class CoalMineRiskModel:
    """
    ç…¤çŸ¿ç“¦æ–¯é£é™©é¢„æµ‹æ¨¡å‹ï¼ˆLightGBMå¤šç›®æ ‡å›å½’ï¼‰
    ä½¿ç”¨ç»„åˆæ¨¡å¼è€Œéç»§æ‰¿æ¥æ•´åˆå„åŠŸèƒ½æ¨¡å—
    """

    def __init__(self, config_path="config.ini",
                 fault_calculator=None,
                 regional_calculator=None,
                 data_preprocessor=None,
                 model_trainer=None,
                 model_evaluator=None,
                 model_predictor=None,
                 model_manager=None,
                 db_utils=None):
        """
        æ¨¡å‹åˆå§‹åŒ–å…¥å£ï¼šè¯»å–é…ç½®â†’åˆå§‹åŒ–ç›®å½•â†’åŠ è½½å‚æ•°â†’åˆå§‹åŒ–ä¾èµ–â†’åŠ è½½å·²æœ‰æ¨¡å‹
        """
        # Step 1: åˆå§‹åŒ–é…ç½®
        self.config_path = config_path
        self.config = configparser.ConfigParser()
        self.config.read(config_path, encoding="utf-8")
        logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶ï¼š{config_path}")
        # Step 2: åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å—
        self.config_utils = ConfigUtils(config_path)
        self.fault_calculator = fault_calculator or FaultCalculator(config_path)
        self.regional_calculator = regional_calculator or RegionalMeasureCalculator(config_path)
        self.data_preprocessor = data_preprocessor or DataPreprocessor(config_path)
        self.model_trainer = model_trainer or ModelTrainer(self.config)
        self.model_trainer.config_filename = os.path.basename(config_path)
        self.model_evaluator = model_evaluator or ModelEvaluator(config_path)
        self.model_predictor = model_predictor or ModelPredictor()
        # Step 3: åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        self.model_dir = self.config_utils._get_config_value("Model", "model_dir", "models")
        self.model_manager = model_manager or ModelManager(self.model_dir)
        # Step 4: åŠ è½½è®­ç»ƒæ ¸å¿ƒå‚æ•°
        self.full_train_threshold = self.config_utils._get_config_value("Model", "full_train_threshold", 6, is_int=True)
        self.min_train_samples = self.config_utils._get_config_value("Model", "min_train_samples", 6, is_int=True)
        # Step 5: æ¨¡å‹æ ¸å¿ƒçŠ¶æ€åˆå§‹åŒ–
        self.models = {}
        self.preprocessor = None
        self.training_features = None
        self.is_trained = False
        self.total_samples = 0
        self.eval_history = []
        self.training_stats = []
        self.baseline_rmse = None
        self._fitted_feature_order = None
        # Step 6: åˆå§‹åŒ–æ•°æ®åº“å·¥å…·ä¸è·¨è¿›ç¨‹é”
        self.db = DBUtils(config_path=config_path)
        self.file_lock = FileLock(self.model_manager.lock_file_path)
        logger.info(f"è·¨è¿›ç¨‹é”åˆå§‹åŒ–å®Œæˆï¼Œé”æ–‡ä»¶è·¯å¾„ï¼š{self.model_manager.lock_file_path}")
        # Step 7: åŠ è½½å·²æœ‰æ¨¡å‹ä¸åŒæ­¥æ•°æ®åº“æ ·æœ¬æ•°
        self._load_model()
        try:
            self.total_samples = self.model_manager.get_total_samples_from_db(self.db)
        except Exception as e:
            self.total_samples = 0
            logger.warning(f"åŒæ­¥æ•°æ®åº“æ ·æœ¬æ•°å¤±è´¥ï¼š{str(e)}ï¼Œåˆå§‹åŒ–ä¸º0")
        # Step 8: æ§åˆ¶å°è¾“å‡ºåˆå§‹åŒ–ç»“æœ
        self._print_header("æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        self.current_config = config_path  # è®°å½•å½“å‰ä½¿ç”¨çš„é…ç½®æ–‡ä»¶
        # ============ 20251218 æ–°å¢ï¼šè¿›å°ºç‰¹å¾çŠ¶æ€åˆå§‹åŒ– ============
        self.mining_advance_enabled = getattr(self.data_preprocessor, 'enable_cumulative_advance', False)
        logger.info(f"è¿›å°ºç‰¹å¾çŠ¶æ€ï¼š{'å·²å¯ç”¨' if self.mining_advance_enabled else 'å·²ç¦ç”¨'}")
        # ============ æ–°å¢ç»“æŸ ============
        logger.info(f"å½“å‰é…ç½®æ–‡ä»¶ï¼š{self.current_config}")
        # æ·»åŠ ç¼ºå¤±çš„å±æ€§åˆå§‹åŒ–
        self.fixed_evaluation_set = None  # å›ºå®šè¯„ä¼°æ•°æ®é›†
        if self.config.getboolean("Logging", "verbose_console", fallback=True):
            # ç¡®ä¿è¿™äº›å±æ€§å­˜åœ¨
            base_categorical_count = len(getattr(self.data_preprocessor, 'base_categorical', []))
            base_numeric_count = len(getattr(self.data_preprocessor, 'base_numeric', []))
            target_features_count = len(getattr(self.data_preprocessor, 'target_features', []))
            algorithm = getattr(self.model_trainer, 'algorithm', 'lightgbm')
            print(f"â”œâ”€ åˆ†ç±»ç‰¹å¾æ•°é‡ï¼š{base_categorical_count}")
            print(f"â”œâ”€ æ•°å€¼ç‰¹å¾æ•°é‡ï¼š{base_numeric_count}")
            print(f"â”œâ”€ é¢„æµ‹ç›®æ ‡æ•°é‡ï¼š{target_features_count}")
            print(f"â”œâ”€ ç´¯è®¡æ ·æœ¬æ•°ï¼š{self.total_samples}")
            print(f"â”œâ”€ ä½¿ç”¨ç®—æ³•ï¼š{algorithm}")
            print(f"â””â”€ æ¨¡å‹çŠ¶æ€ï¼š{'å·²è®­ç»ƒ' if self.is_trained else 'æœªè®­ç»ƒ'}")
            print("=" * 60)
            # ============ 20251218æ–°å¢ï¼šè¾“å‡ºè¿›å°ºç‰¹å¾çŠ¶æ€ ============
            if hasattr(self.data_preprocessor, 'enable_cumulative_advance'):
                print(f"â”œâ”€ è¿›å°ºç‰¹å¾ï¼š{'å·²å¯ç”¨' if self.data_preprocessor.enable_cumulative_advance else 'å·²ç¦ç”¨'}")
            # ============ æ–°å¢ç»“æŸ ============

    def reload_config(self, new_config_path=None, reload_database=False):
        """
        åŠ¨æ€é‡è½½é…ç½®ï¼ˆä¸é‡å¯æœåŠ¡ï¼‰
        ä¿æŒåŸæœ‰æ¨¡å‹çŠ¶æ€ï¼Œåªæ›´æ–°é…ç½®å‚æ•°

        :param new_config_path: strï¼Œæ–°é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤Noneï¼ˆä½¿ç”¨å½“å‰è·¯å¾„ï¼‰
        :param reload_database: boolï¼Œæ˜¯å¦é‡è½½æ•°æ®åº“é…ç½®ï¼Œé»˜è®¤Falseï¼ˆé¿å…ä¸å¿…è¦çš„è¿æ¥é‡å»ºï¼‰
        :return: boolï¼Œé‡è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åŠ¨æ€é‡è½½ç³»ç»Ÿé…ç½®")
            # Step 1: å¤‡ä»½å…³é”®çŠ¶æ€
            current_models = self.models.copy() if self.models else {}
            current_total_samples = self.total_samples
            current_training_stats = self.training_stats.copy() if hasattr(self, 'training_stats') else []
            current_eval_history = self.eval_history.copy() if hasattr(self, 'eval_history') else []
            current_baseline_rmse = self.baseline_rmse if hasattr(self, 'baseline_rmse') else None
            current_is_trained = self.is_trained
            current_preprocessor = self.preprocessor
            current_training_features = self.training_features
            current_fitted_feature_order = self._fitted_feature_order
            current_modules = {
                'fault_calculator': self.fault_calculator,
                'regional_calculator': self.regional_calculator,
                'data_preprocessor': self.data_preprocessor,
                'model_trainer': self.model_trainer,
                'model_evaluator': self.model_evaluator,
                'model_manager': self.model_manager,
                'db': self.db
            }
            # ============ 20251218æ–°å¢ï¼šé‡è½½è¿›å°ºé…ç½® ============
            # é‡æ–°åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨ï¼ˆä¼šé‡æ–°åŠ è½½è¿›å°ºé…ç½®ï¼‰
            self.data_preprocessor = DataPreprocessor(self.config_path)

            # æ›´æ–°è¿›å°ºç‰¹å¾çŠ¶æ€
            self.mining_advance_enabled = getattr(self.data_preprocessor, 'enable_cumulative_advance', False)
            logger.info(f"è¿›å°ºç‰¹å¾é…ç½®é‡è½½ï¼š{'å·²å¯ç”¨' if self.mining_advance_enabled else 'å·²ç¦ç”¨'}")
            # ============ 20251218æ–°å¢ç»“æŸ ============
            # Step 2: æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›äº†æ–°è·¯å¾„ï¼‰
            if new_config_path:
                self.config_path = new_config_path
                logger.info(f"åˆ‡æ¢åˆ°æ–°é…ç½®æ–‡ä»¶: {new_config_path}")
            # Step 3: é‡æ–°è¯»å–é…ç½®
            merged_config = configparser.ConfigParser()
            # é¦–å…ˆè¯»å–åŸºç¡€é…ç½® config.ini
            merged_config.read("config.ini", encoding="utf-8")
            logger.debug("åŸºç¡€é…ç½®æ–‡ä»¶ config.ini å·²åŠ è½½")

            # ç„¶åè¯»å–é˜¶æ®µé…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå®ƒä¼šè¦†ç›–åŸºç¡€é…ç½®ä¸­çš„ç›¸åŒé¡¹
            if self.config_path and self.config_path != "config.ini":
                stage_config_read = merged_config.read(self.config_path, encoding="utf-8")
                if stage_config_read:
                    logger.debug(f"é˜¶æ®µé…ç½®æ–‡ä»¶ {self.config_path} å·²åŠ è½½å¹¶åˆå¹¶")
                else:
                    logger.warning(f"é˜¶æ®µé…ç½®æ–‡ä»¶ {self.config_path} è¯»å–å¤±è´¥ï¼Œä»…ä½¿ç”¨åŸºç¡€é…ç½®")
            # æ›´æ–°å½“å‰é…ç½®å¯¹è±¡
            self.config = merged_config
            logger.debug("é…ç½®æ–‡ä»¶åˆå¹¶å®Œæˆ")
            # Step 4: é‡æ–°åˆå§‹åŒ–é…ç½®å·¥å…·å’Œå„æ¨¡å—,ä½¿ç”¨åˆå¹¶åçš„é…ç½®å¯¹è±¡æ¥åˆå§‹åŒ–å„æ¨¡å—
            self.config_utils = ConfigUtils(self.config_path)
            # é‡æ–°åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å—
            self.fault_calculator = FaultCalculator(self.config_path)
            self.regional_calculator = RegionalMeasureCalculator(self.config_path)
            self.data_preprocessor = DataPreprocessor(self.config_path)
            self.model_trainer = ModelTrainer(self.config)
            self.model_evaluator = ModelEvaluator(self.config_path)
            self.model_manager = ModelManager(self.model_dir)
            # Step 5: æ¡ä»¶æ€§é‡è½½æ•°æ®åº“é…ç½®
            if reload_database:
                logger.info("é‡è½½æ•°æ®åº“é…ç½®ï¼ˆå°†é‡å»ºæ•°æ®åº“è¿æ¥ï¼‰")
                db_reload_success = self.db.reload_config(self.config_path)
                if not db_reload_success:
                    logger.error("æ•°æ®åº“é…ç½®é‡è½½å¤±è´¥ï¼Œä½†ç»§ç»­å…¶ä»–é…ç½®é‡è½½")
            else:
                logger.info("è·³è¿‡æ•°æ®åº“é…ç½®é‡è½½ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥ï¼‰")
            # Step 6: é‡æ–°åŠ è½½æ¨¡å‹æ ¸å¿ƒå‚æ•°
            self.full_train_threshold = self.config_utils._get_config_value("Model", "full_train_threshold", 6,is_int=True)
            self.min_train_samples = self.config_utils._get_config_value("Model", "min_train_samples", 6,is_int=True)
            # Step 7: æ¢å¤å…³é”®çŠ¶æ€
            self.models = current_models
            self.total_samples = current_total_samples
            self.training_stats = current_training_stats
            self.eval_history = current_eval_history
            self.baseline_rmse = current_baseline_rmse
            self.is_trained = current_is_trained
            self.preprocessor = current_preprocessor
            self.training_features = current_training_features
            self._fitted_feature_order = current_fitted_feature_order
            # Step 8: åŒæ­¥é¢„å¤„ç†å™¨çŠ¶æ€
            if hasattr(self.data_preprocessor, 'is_trained'):
                self.data_preprocessor.is_trained = current_is_trained
            if hasattr(self.data_preprocessor, 'training_features') and self.training_features:
                self.data_preprocessor.training_features = self.training_features
            if hasattr(self, 'model_trainer'):
                self.model_trainer.config_filename = os.path.basename(self.config_path)
            logger.info("é…ç½®åŠ¨æ€é‡è½½å®Œæˆï¼Œæ‰€æœ‰æ¨¡å—å·²æ›´æ–°")
            self._print_result("é…ç½®åŠ¨æ€é‡è½½æˆåŠŸ")
            # è¾“å‡ºæ–°çš„å…³é”®å‚æ•°å€¼
            if self.config.getboolean("Logging", "verbose_console", fallback=True):
                print(f"â”œâ”€ æ–°çš„å…¨é‡è®­ç»ƒé˜ˆå€¼: {self.full_train_threshold}")
                print(f"â”œâ”€ æ–°çš„æœ€å°æ ·æœ¬æ•°: {self.min_train_samples}")
                print(f"â”œâ”€ æ–°çš„æ ‘æ•°é‡: {self.model_trainer.n_estimators}")
                print(f"â”œâ”€ æ–°çš„å­¦ä¹ ç‡: {self.model_trainer.learning_rate}")
                if reload_database:
                    print(f"â””â”€ æ•°æ®åº“é…ç½®å·²é‡è½½")
                else:
                    print(f"â””â”€ æ•°æ®åº“é…ç½®æœªé‡è½½ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥ï¼‰")
            return True
        except Exception as e:
            logger.error(f"é…ç½®åŠ¨æ€é‡è½½å¤±è´¥ï¼Œæ­£åœ¨æ¢å¤çŠ¶æ€ï¼š{str(e)}", exc_info=True)
            # æ¢å¤æ¨¡å—çŠ¶æ€
            self.fault_calculator = current_modules['fault_calculator']
            self.regional_calculator = current_modules['regional_calculator']
            self.data_preprocessor = current_modules['data_preprocessor']
            self.model_trainer = current_modules['model_trainer']
            self.model_evaluator = current_modules['model_evaluator']
            self.model_manager = current_modules['model_manager']
            self.db = current_modules['db']
            self._print_result(f"é…ç½®é‡è½½å¤±è´¥ï¼š{str(e)}")
            return False
    def _print_header(self, title):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_header(title)

    def _print_step(self, msg):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_step(msg)

    def _print_result(self, msg):
        """å§”æ‰˜ç»™config_utils"""
        self.config_utils._print_result(msg)

    def _load_model(self):
        """åŠ è½½å·²æœ‰æ¨¡å‹ç»„ä»¶"""
        self._print_header("åŠ è½½å·²æœ‰æ¨¡å‹")
        try:
            # ç¡®ä¿target_featureså±æ€§å­˜åœ¨
            target_features = getattr(self.data_preprocessor, 'target_features', [])
            if not target_features:
                logger.warning("ç›®æ ‡ç‰¹å¾åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
                self.is_trained = False
                return
            (self.preprocessor, self.training_features,
             self.models, self.is_trained) = self.model_manager.load_model(target_features)
            if self.is_trained:
                self.data_preprocessor.is_trained = True
                self.data_preprocessor.training_features = self.training_features
                self._print_step("æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                self._print_step("æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æœªè®­ç»ƒï¼Œéœ€ä»å¤´è®­ç»ƒ")
        except Exception as e:
            self.is_trained = False
            logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}", exc_info=True)
            self._print_step(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼Œéœ€ä»å¤´è®­ç»ƒ")
        finally:
            if self.config.getboolean("Logging", "verbose_console", fallback=True):
                print("-" * 60)

    def calculate_fault_influence_strength(self, data):
        """è®¡ç®—æ–­å±‚å½±å“ç³»æ•°ï¼ˆå§”æ‰˜ç»™FaultCalculatorï¼‰"""
        return self.fault_calculator.calculate_fault_influence_strength(data, self.db)

    def calculate_regional_measure_strength(self, measures):
        """è®¡ç®—åŒºåŸŸæªæ–½å¼ºåº¦ï¼ˆå§”æ‰˜ç»™RegionalMeasureCalculatorï¼‰"""
        return self.regional_calculator.calculate_regional_measure_strength(measures)

    def _preprocess_data(self, data, is_training=True):
        """æ•°æ®é¢„å¤„ç†ï¼ˆå§”æ‰˜ç»™DataPreprocessorï¼‰"""
        if is_training:
            df, training_features = self.data_preprocessor.preprocess_data(
                data, is_training, self.fault_calculator, self.db
            )
            self.training_features = training_features
            return df
        else:
            return self.data_preprocessor.preprocess_data(
                data, is_training, self.fault_calculator, self.db
            )

    def _print_training_diagnosis(self):
        """
        æ–°å¢ï¼šæ‰“å°è®­ç»ƒè¯Šæ–­ç»“æœå’Œå‚æ•°å»ºè®®
        ä¸ä¿®æ”¹åŸæœ‰è®­ç»ƒæµç¨‹
        """
        training_details = self.model_trainer.get_last_training_diagnostics()
        if not training_details:
            return
        target_performance = training_details.get('target_performance', {})
        suggestions = training_details.get('parameter_suggestions', [])
        self._print_header("æ¨¡å‹è®­ç»ƒè¯Šæ–­ç»“æœ")
        # æ‰“å°å„ç›®æ ‡æ€§èƒ½
        for target, perf in target_performance.items():
            status = "âœ… è‰¯å¥½"
            if perf.get('is_overfitting', False):
                status = "âš ï¸ è¿‡æ‹Ÿåˆ"
            elif perf.get('is_underfitting', False):
                status = "ğŸ“‰ æ¬ æ‹Ÿåˆ"
            validation_note = "(éªŒè¯é›†)" if perf.get('use_validation', False) else "(è®­ç»ƒé›†)"
            self._print_step(
                f"{target}: è®­ç»ƒRMSE={perf['train_rmse']}, "
                f"{validation_note}RMSE={perf['val_rmse']}, "
                f"è¿‡æ‹Ÿåˆæ¯”ç‡={perf['overfitting_ratio']} {status}"
            )
        # æ‰“å°å‚æ•°å»ºè®®
        if suggestions:
            self._print_header("å‚æ•°è°ƒæ•´å»ºè®®")
            for suggestion in suggestions:
                self._print_step(suggestion)

    # ============ 20251218æ–°å¢ï¼šè¿›å°ºç‰¹å¾è¾…åŠ©æ–¹æ³• ============
    def _validate_and_log_mining_features(self, df):
        """
        éªŒè¯å’Œè®°å½•è¿›å°ºç‰¹å¾ä¿¡æ¯
        :param df: é¢„å¤„ç†åçš„DataFrame
        """
        try:
            # æ£€æŸ¥è¿›å°ºç‰¹å¾æ˜¯å¦å­˜åœ¨
            required_features = ['cumulative_advance', 'effective_exposure_distance']
            missing_features = [f for f in required_features if f not in df.columns]
            if missing_features:
                logger.warning(f"è¿›å°ºç‰¹å¾ç¼ºå¤±ï¼š{missing_features}")
            else:
                # è®°å½•è¿›å°ºç‰¹å¾ç»Ÿè®¡
                cum_stats = {
                    'min': df['cumulative_advance'].min(),
                    'max': df['cumulative_advance'].max(),
                    'mean': df['cumulative_advance'].mean()
                }
                exp_stats = {
                    'min': df['effective_exposure_distance'].min(),
                    'max': df['effective_exposure_distance'].max(),
                    'mean': df['effective_exposure_distance'].mean()
                }
                logger.info(
                    f"è¿›å°ºç‰¹å¾ç»Ÿè®¡ï¼šç´¯è®¡è¿›å°º[{cum_stats['min']:.1f}~{cum_stats['max']:.1f}], "
                    f"å‡å€¼={cum_stats['mean']:.1f}; "
                    f"æœ‰æ•ˆæš´éœ²è·ç¦»[{exp_stats['min']:.1f}~{exp_stats['max']:.1f}], "
                    f"å‡å€¼={exp_stats['mean']:.1f}"
                )
                # æ§åˆ¶å°è¾“å‡º
                if self.config.getboolean("Logging", "verbose_console", fallback=True):
                    print("â”œâ”€ è¿›å°ºç‰¹å¾ç»Ÿè®¡ï¼š")
                    print(
                        f"â”‚  â”œâ”€ ç´¯è®¡è¿›å°ºï¼š{cum_stats['min']:.1f}~{cum_stats['max']:.1f}ç±³ï¼Œå‡å€¼={cum_stats['mean']:.1f}ç±³")
                    print(
                        f"â”‚  â”œâ”€ æœ‰æ•ˆæš´éœ²è·ç¦»ï¼š{exp_stats['min']:.1f}~{exp_stats['max']:.1f}ç±³ï¼Œå‡å€¼={exp_stats['mean']:.1f}ç±³")
        except Exception as e:
            logger.warning(f"è¿›å°ºç‰¹å¾éªŒè¯å¤±è´¥ï¼š{str(e)}")
    # ============ 20251218æ–°å¢ç»“æŸ ============
    def train(self, data, epochs=1):
        """
        å…¬å¼€æ–¹æ³•ï¼šæ¨¡å‹è®­ç»ƒæ¥å£
        """
        with self.file_lock:
            self._print_header("æ¨¡å‹è®­ç»ƒå¼€å§‹")
            train_start = datetime.now()
            initial_samples = self.total_samples
            db_conn = None
            db_trans = None
            custom_create_time = None
            saved_count = 0
            try:
                # Step 1: æ•°æ®é¢„å¤„ç†
                df = self._preprocess_data(data, is_training=True)
                # ============ 20251218 æ–°å¢ï¼šæ—¶ç©ºç‰¹å¾éªŒè¯ä¸è®°å½• ============
                if hasattr(self.data_preprocessor, 'spatiotemporal_extractor') and \
                        self.data_preprocessor.spatiotemporal_extractor:
                    # è·å–æ–°å¢çš„æ—¶ç©ºç‰¹å¾ä¿¡æ¯
                    new_features = self.data_preprocessor.spatiotemporal_extractor.get_new_feature_names()
                    if new_features:
                        logger.info(f"æœ¬æ¬¡è®­ç»ƒä½¿ç”¨äº† {len(new_features)} ä¸ªæ—¶ç©ºç‰¹å¾")

                        # æŒ‰ç±»åˆ«ç»Ÿè®¡
                        categories = self.data_preprocessor.spatiotemporal_extractor.get_all_new_feature_categories()
                        for category, features in categories.items():
                            if features:
                                logger.debug(f"  {category}: {len(features)}ä¸ªç‰¹å¾")

                        # æ§åˆ¶å°è¾“å‡º
                        if self.config.getboolean("Logging", "verbose_console", fallback=True):
                            print(f"â”œâ”€ æ—¶ç©ºç‰¹å¾ä½¿ç”¨æƒ…å†µï¼š")
                            for category, features in categories.items():
                                if features:
                                    print(f"â”‚  â”œâ”€ {category}: {len(features)}ä¸ª")
                # ============ 20251218 æ–°å¢ç»“æŸï¼šæ—¶ç©ºç‰¹å¾éªŒè¯ä¸è®°å½• ============
                if self.mining_advance_enabled:
                    self._validate_and_log_mining_features(df)
                # ============ 20251218æ–°å¢ç»“æŸ ============
                if len(df) < self.min_train_samples:
                    msg = f"æ ·æœ¬æ•° {len(df)} < æœ€å°è®­ç»ƒæ ·æœ¬æ•° {self.min_train_samples}ï¼Œè·³è¿‡è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": len(df), "training_performed": False}
                    }
                # ============ æ–°å¢ï¼šè‡ªåŠ¨é…ç½®åˆ‡æ¢é€»è¾‘ ============
                # åˆ¤æ–­æ˜¯å¦åˆæ¬¡è®­ç»ƒï¼ˆæ¨¡å‹æœªè®­ç»ƒä¸”æ•°æ®åº“æ ·æœ¬æ•°ä¸º0ï¼‰
                is_initial_training = not self.is_trained and initial_samples == 0
                # åˆ¤æ–­æ•°æ®é‡å¤§å°ï¼ˆä½¿ç”¨å…¨é‡è®­ç»ƒé˜ˆå€¼ä½œä¸ºåˆ¤æ–­æ ‡å‡†ï¼‰
                is_large_data = len(df) >= self.full_train_threshold
                # è‡ªåŠ¨é…ç½®åˆ‡æ¢å†³ç­–
                if is_initial_training and is_large_data:
                    # åˆæ¬¡å¤§é‡æ•°æ®è®­ç»ƒ â†’ ä½¿ç”¨ phase1 é…ç½®
                    target_config = "config_phase1.ini"
                    reason = "åˆæ¬¡å¤§é‡æ•°æ®è®­ç»ƒ"
                elif self.is_trained and not is_large_data:
                    # åç»­å°‘é‡æ•°æ®å¢é‡è®­ç»ƒ â†’ ä½¿ç”¨ phase2 é…ç½®
                    target_config = "config_phase2.ini"
                    reason = "å°‘é‡æ•°æ®å¢é‡è®­ç»ƒ"
                else:
                    # å…¶ä»–æƒ…å†µä¿æŒå½“å‰é…ç½®
                    target_config = None
                    reason = "ä¿æŒå½“å‰é…ç½®"
                # æ‰§è¡Œé…ç½®åˆ‡æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if target_config and getattr(self, 'current_config', None) != target_config:
                    logger.info(f"è‡ªåŠ¨é…ç½®åˆ‡æ¢ï¼š{reason} â†’ {target_config}")
                    success = self.reload_config(target_config)
                    if success:
                        self.current_config = target_config
                        self.model_trainer.config_filename = os.path.basename(target_config)
                        self._print_step(f"âœ… é…ç½®å·²åˆ‡æ¢ï¼š{target_config}ï¼ˆ{reason}ï¼‰")
                    else:
                        logger.error(f"é…ç½®åˆ‡æ¢å¤±è´¥ï¼š{target_config}")
                        self._print_step(f"âŒ é…ç½®åˆ‡æ¢å¤±è´¥ï¼š{target_config}")
                elif target_config:
                    logger.debug(f"é…ç½®å·²æ˜¯æœ€æ–°ï¼š{target_config}")
                else:
                    logger.debug(f"æ— éœ€åˆ‡æ¢é…ç½®ï¼š{reason}")
                # ============ è‡ªåŠ¨é…ç½®åˆ‡æ¢é€»è¾‘ç»“æŸ ============
                # Step 2: å¼€å¯æ•°æ®åº“äº‹åŠ¡
                db_conn = self.db._get_connection()
                db_trans = db_conn.begin()
                logger.info("æ•°æ®åº“äº‹åŠ¡å·²å¼€å¯ï¼Œå‡†å¤‡ä¿å­˜è®­ç»ƒæ•°æ®")
                # Step 3: ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
                custom_create_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
                saved_count = self.db.save_training_data(
                    df=df,
                    conn=db_conn,
                    trans=db_trans,
                    custom_create_time=custom_create_time
                )
                if saved_count == 0:
                    raise ValueError("æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥ï¼ˆä¿å­˜æ¡æ•°ä¸º0ï¼‰")
                logger.info(f"äº‹åŠ¡ä¸­æ’å…¥ {saved_count} æ¡è®­ç»ƒæ•°æ®ï¼ˆæœªæäº¤ï¼‰")

                # Step 4: æ„å»ºè®­ç»ƒé›†
                if not self.training_features:
                    raise ValueError("è®­ç»ƒç‰¹å¾åˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†")
                X = df[self.training_features]
                y = df[self.data_preprocessor.target_features].values
                self._fitted_feature_order = X.columns.tolist()
                # è®°å½•ç‰¹å¾ä¿¡æ¯
                logger.info(
                    f"è®­ç»ƒç‰¹å¾æ•°é‡: {len(self.training_features)}ï¼ŒåŒ…å«æ—¶ç©ºç‰¹å¾: {any('neighbor_' in f or 'decay' in f for f in self.training_features)}")
                # Step 5: ç‰¹å¾é¢„å¤„ç†
                self.preprocessor, X_proc, _ = self.model_trainer.create_preprocessor(X, self.data_preprocessor.base_categorical)

                # Step 6: åˆ¤æ–­è®­ç»ƒæ¨¡å¼
                current_total = initial_samples + len(df)
                threshold_hit = (current_total % self.full_train_threshold == 0)
                # ä¼ é€’æ•°æ®é‡ä¿¡æ¯çš„æ€§èƒ½æ£€æŸ¥
                perf_trigger = self.model_evaluator._performance_trigger_check(
                    self.eval_history,
                    self.baseline_rmse,
                    len(df)  # ä¼ é€’å½“å‰è®­ç»ƒæ•°æ®é‡
                )
                if perf_trigger:
                    do_full_train = True
                    reason = "æ€§èƒ½ä¸‹é™è§¦å‘"
                elif threshold_hit:
                    do_full_train = True
                    reason = "æ ·æœ¬æ•°è¾¾é˜ˆå€¼è§¦å‘"
                elif not self.is_trained:
                    do_full_train = True
                    reason = "é¦–æ¬¡è®­ç»ƒ"
                else:
                    do_full_train = False
                    reason = "å¢é‡è®­ç»ƒ"
                self._print_step(f"è®­ç»ƒæ¨¡å¼åˆ¤æ–­ï¼š{reason}")
                # Step 7: æ‰§è¡Œè®­ç»ƒ
                if do_full_train:
                    self.models = self.model_trainer._full_train(X_proc, y, self.data_preprocessor.target_features)
                else:
                    self.models = self.model_trainer._incremental_train(X_proc, y, self.data_preprocessor.target_features, self.models)
                # Step 8: æäº¤äº‹åŠ¡+æ›´æ–°çŠ¶æ€
                db_trans.commit()
                logger.info(f"äº‹åŠ¡æäº¤æˆåŠŸï¼Œ{saved_count} æ¡æ•°æ®å·²æŒä¹…åŒ–")
                self.total_samples = self.model_manager.get_total_samples_from_db(self.db)
                new_samples = self.total_samples - initial_samples
                self._print_step(f"æ ·æœ¬æ•°æ›´æ–°ï¼šæ–°å¢ {new_samples} æ¡ï¼Œç´¯è®¡ {self.total_samples} æ¡")
                # Step 9: ä¿å­˜æ¨¡å‹+æ ‡è®°è®­ç»ƒçŠ¶æ€
                self.model_manager.save_model(self.models, self.preprocessor, self.training_features, self.data_preprocessor.target_features)
                self.is_trained = True
                # åŒæ­¥çŠ¶æ€åˆ°é¢„å¤„ç†å™¨
                self.data_preprocessor.is_trained = True
                self.data_preprocessor.training_features = self.training_features
                # Step 10: è®­ç»ƒåè¯„ä¼°ï¼ˆå°æ•°æ®ç‰¹æ®Šå¤„ç†ï¼‰
                if len(df) <= 5:
                    # æå°‘é‡æ•°æ®ï¼šè·³è¿‡è¯„ä¼°ï¼Œé¿å…ä¸å‡†ç¡®çš„RMSEå½±å“åŸºçº¿
                    eval_result = {
                        "status": "skipped",
                        "message": f"æ•°æ®é‡è¿‡å°‘({len(df)}æ¡)ï¼Œè·³è¿‡è¯„ä¼°é¿å…è¯¯åˆ¤",
                        "avg_rmse": None
                    }
                    agg_rmse = None
                    logger.info(f"å°æ•°æ®è®­ç»ƒ({len(df)}æ¡)ï¼šè·³è¿‡æ€§èƒ½è¯„ä¼°")
                else:
                    # æ­£å¸¸æ•°æ®é‡ï¼šæ‰§è¡Œè¯„ä¼°
                    eval_result = self.evaluate_model()
                    agg_rmse = eval_result.get("avg_rmse")

                # Step 11: æ™ºèƒ½è®¾ç½®æ€§èƒ½åŸºçº¿
                if agg_rmse and self.baseline_rmse is None:
                    # é¦–æ¬¡è®¾ç½®åŸºçº¿
                    self.baseline_rmse = agg_rmse
                    logger.info(f"è®¾ç½®åˆå§‹æ€§èƒ½åŸºçº¿: {agg_rmse:.4f}")
                elif agg_rmse and len(df) >= 10:
                    # åªæœ‰æ•°æ®é‡è¶³å¤Ÿæ—¶æ‰æ›´æ–°åŸºçº¿ï¼Œé¿å…å°æ•°æ®å¹²æ‰°
                    self.baseline_rmse = agg_rmse
                    logger.info(f"æ›´æ–°æ€§èƒ½åŸºçº¿: {agg_rmse:.4f}")

                # Step 12: æ€§èƒ½å›æ»šæ£€æŸ¥ï¼ˆæ·»åŠ å°æ•°æ®ä¿æŠ¤ï¼‰
                # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡å agg_rmse è€Œä¸æ˜¯ current_rmse
                if (eval_result["status"] == "success" and
                        agg_rmse is not None and  # ä¿®æ­£ï¼šä½¿ç”¨ agg_rmse
                        self.baseline_rmse is not None and
                        len(df) > 10):  # åªæœ‰æ•°æ®é‡>10æ—¶æ‰æ£€æŸ¥æ€§èƒ½ä¸‹é™
                    drop_ratio = (agg_rmse - self.baseline_rmse) / self.baseline_rmse  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡
                    # æ·»åŠ è¯¦ç»†çš„æ€§èƒ½è¯Šæ–­æ—¥å¿—
                    logger.info(f"=== æ€§èƒ½æ£€æŸ¥è¯Šæ–­ ===")
                    logger.info(f"è®­ç»ƒæ•°æ®: {len(df)}æ¡, å½“å‰RMSE: {agg_rmse:.4f}")  # ä¿®æ­£ï¼šä½¿ç”¨ agg_rmse
                    logger.info(f"åŸºçº¿RMSE: {self.baseline_rmse:.4f}, ä¸‹é™æ¯”ä¾‹: {drop_ratio:.2%}")
                    logger.info(f"é˜ˆå€¼: {self.model_evaluator.perf_drop_ratio * 2:.2%}")
                    if drop_ratio > self.model_evaluator.perf_drop_ratio * 2:
                        logger.warning(f"æ€§èƒ½ä¸‹é™è¿‡å¤šï¼ˆ{drop_ratio:.2%}ï¼‰ï¼Œå°è¯•å›æ»š")
                        rollback_res = self.rollback_model(backup_index=-2)
                        if rollback_res["success"]:
                            # é‡æ–°åŠ è½½æ¨¡å‹
                            self._load_model()
                            # æ›´æ–°åŸºçº¿
                            if self.eval_history and len(self.eval_history) > 1:
                                self.baseline_rmse = self.eval_history[-2]["avg_rmse"]
                            logger.info(f"å›æ»šæˆåŠŸï¼ŒåŸºçº¿RMSEæ¢å¤ä¸ºï¼š{self.baseline_rmse}")
                else:
                    skip_reason = []
                    if eval_result["status"] != "success":
                        skip_reason.append("è¯„ä¼°å¤±è´¥")
                    if agg_rmse is None:
                        skip_reason.append("æ— RMSEæ•°æ®")
                    if self.baseline_rmse is None:
                        skip_reason.append("æ— åŸºçº¿æ•°æ®")
                    if len(df) <= 10:
                        skip_reason.append("å°æ•°æ®è®­ç»ƒ")
                    logger.info(f"è·³è¿‡æ€§èƒ½å›æ»šæ£€æŸ¥: {', '.join(skip_reason)}")
                # Step 13: å¦‚æœæ˜¯å¤§æ•°æ®é‡åˆå§‹è®­ç»ƒï¼Œè®¾ç½®å›ºå®šè¯„ä¼°é›†
                if len(df) >= 100 and not hasattr(self, 'fixed_evaluation_set'):
                    logger.info("å¤§æ•°æ®é‡è®­ç»ƒï¼Œè®¾ç½®å›ºå®šè¯„ä¼°é›†")
                    self.set_fixed_evaluation_set(df, size=50)
                # Step 12: è®°å½•è®­ç»ƒå†å²åˆ°æ•°æ®åº“
                train_duration = (datetime.now() - train_start).total_seconds()
                # ç›‘æ§è°ƒç”¨
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode=reason,  # ä»åŸæœ‰å˜é‡è·å–
                    sample_count=len(df),  # ä»åŸæœ‰å˜é‡è·å–
                    duration=train_duration,
                    rmse=agg_rmse  # ä»åŸæœ‰å˜é‡è·å–
                )
                training_record = {
                    "sample_count": len(df),
                    "total_samples": self.total_samples,
                    "train_mode": reason,
                    "status": "success",
                    "message": f"è®­ç»ƒå®Œæˆï¼ˆ{reason}ï¼‰ï¼ŒRMSEï¼š{agg_rmse:.4f}" if agg_rmse else f"è®­ç»ƒå®Œæˆï¼ˆ{reason}ï¼‰ï¼ŒRMSEï¼šæœªè®¡ç®—",
                    "duration": train_duration,
                    "train_time": datetime.now()
                }
                record_id = self.db.insert_training_record(training_record)
                # æ„å»ºè¿”å›ç»“æœ
                training_result = {
                    "status": "success",
                    "message": f"è®­ç»ƒå®Œæˆï¼ˆæ¨¡å¼ï¼š{reason}ï¼‰",
                    "training_stats": {
                        "processed_samples": len(df),
                        "saved_to_db": saved_count,
                        "new_samples": new_samples,
                        "total_samples": self.total_samples,
                        "training_mode": reason,
                        "evaluation_rmse": agg_rmse,
                        "training_duration": round(train_duration, 2),
                        "record_id": record_id,
                        "mining_features_enabled": self.mining_advance_enabled,
                        "mining_features_calculated": 'cumulative_advance' in df.columns,
                        "mining_samples_count": df[
                        'daily_advance'].notnull().sum() if 'daily_advance' in df.columns else 0,
                        # ============ 20251218æ–°å¢æ—¶ç©ºç‰¹å¾ç»Ÿè®¡ ============
                        "spatiotemporal_features_enabled": hasattr(self.data_preprocessor,
                                                                   'spatiotemporal_extractor') and \
                                                           self.data_preprocessor.spatiotemporal_extractor is not None,
                        "spatiotemporal_feature_count": len(new_features) if 'new_features' in locals() else 0,
                        "feature_categories": categories if 'categories' in locals() else {}
                        # ============ 20251218æ–°å¢ç»“æŸ ============
                    },
                    "evaluation_details": eval_result if eval_result.get("status") == "success" else None
                }
                rmse_str = f"{agg_rmse:.4f}" if agg_rmse is not None else "æ— è¯„ä¼°æ•°æ®"
                logger.info(f"è®­ç»ƒåè¯„ä¼°RMSE: {rmse_str}")
                # ============ åªåœ¨è®­ç»ƒæˆåŠŸå®Œæˆåæ·»åŠ è¯Šæ–­ä¿¡æ¯è¾“å‡º ============
                if training_result.get("status") == "success":
                    # è¾“å‡ºè®­ç»ƒè¯Šæ–­ä¿¡æ¯
                    self._print_training_diagnosis()
                return training_result
            except Exception as e:
                # è®­ç»ƒå¤±è´¥ â†’ å›æ»šäº‹åŠ¡
                logger.error(f"è®­ç»ƒå¤±è´¥ï¼Œè§¦å‘å›æ»šï¼š{str(e)}", exc_info=True)
                # è®­ç»ƒå¤±è´¥æ—¶ä¹Ÿè®°å½•ç›‘æ§
                train_duration = (datetime.now() - train_start).total_seconds()
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="failed",
                    sample_count=len(df) if 'df' in locals() else 0,
                    duration=train_duration,
                    rmse=None
                )
                if db_trans:
                    try:
                        db_trans.rollback()
                        logger.info("äº‹åŠ¡å·²å›æ»šï¼Œæ— æ®‹ç•™æ•°æ®")
                    except Exception as rollback_e:
                        if custom_create_time and db_conn:
                            from sqlalchemy import text
                            delete_sql = text("DELETE FROM t_prediction_parameters WHERE create_time = :ct")
                            db_conn.execute(delete_sql, {"ct": custom_create_time})
                            db_trans.commit()
                            logger.info(f"æ‰‹åŠ¨åˆ é™¤æ®‹ç•™æ•°æ®ï¼ˆcreate_timeï¼š{custom_create_time}ï¼‰")
                return {
                    "status": "error",
                    "message": str(e),
                    "training_stats": {
                        "processed_samples": len(df) if 'df' in locals() else 0,
                        "saved_to_db": saved_count,
                        "data_rolled_back": True
                    }
                }
            finally:
                if db_conn:
                    try:
                        db_conn.close()
                        logger.debug("è®­ç»ƒæµç¨‹æ•°æ®åº“è¿æ¥å·²å…³é—­")
                    except Exception as close_e:
                        logger.warning(f"å…³é—­è¿æ¥å¤±è´¥ï¼š{str(close_e)}")

    def evaluate_model(self, eval_size=200, eval_df=None, use_fixed_set=False):
        """
        å¢å¼ºçš„æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œæ”¯æŒå›ºå®šè¯„ä¼°é›†
        :param eval_size: è¯„ä¼°æ ·æœ¬æ•°
        :param eval_df: å¤–éƒ¨è¯„ä¼°æ•°æ®
        :param use_fixed_set: æ˜¯å¦ä½¿ç”¨å›ºå®šè¯„ä¼°é›†
        :return: è¯„ä¼°ç»“æœ
        """
        if use_fixed_set and hasattr(self, 'fixed_evaluation_set') and self.fixed_evaluation_set is not None:
            logger.info("ä½¿ç”¨å›ºå®šè¯„ä¼°é›†è¿›è¡Œè¯„ä¼°")
            eval_df = self.fixed_evaluation_set
        return self.model_evaluator.evaluate_model(
            self.models, self.preprocessor, self.training_features, self.data_preprocessor.target_features,
            self._fitted_feature_order, self.db, eval_size, eval_df
        )

    def predict(self, data):
        """
        æ¨¡å‹é¢„æµ‹ï¼ˆå§”æ‰˜ç»™ModelPredictorï¼‰
        æ–°å¢ï¼šæ·»åŠ è¿›å°ºç‰¹å¾çŠ¶æ€
        """
        # ä½¿ç”¨ModelPredictorè¿›è¡Œé¢„æµ‹
        result = self.model_predictor.predict(
            data, self.models, self.preprocessor, self.training_features,
            self.data_preprocessor.target_features, self._fitted_feature_order, self.is_trained,
            self.file_lock, self.data_preprocessor, self.fault_calculator, self.db
        )

        # ============ æ–°å¢ï¼šæ·»åŠ è¿›å°ºç‰¹å¾çŠ¶æ€ ============
        if hasattr(self, 'mining_advance_enabled'):
            # åœ¨ç»“æœä¸­æ·»åŠ è¿›å°ºç‰¹å¾çŠ¶æ€
            if 'success' in result and result['success']:
                result['mining_features'] = {
                    'enabled': self.mining_advance_enabled,
                    'message': 'è¿›å°ºç‰¹å¾å·²å¯ç”¨' if self.mining_advance_enabled else 'è¿›å°ºç‰¹å¾æœªå¯ç”¨'
                }
        # ============ æ–°å¢ç»“æŸ ============
        return result

    def rollback_model(self, backup_index=-1):
        """æ¨¡å‹å›æ»šï¼ˆå§”æ‰˜ç»™ModelManagerï¼‰"""
        result = self.model_manager.rollback_model(backup_index, self.data_preprocessor.target_features)
        if result["success"]:
            # é‡æ–°åŠ è½½æ¨¡å‹
            self._load_model()
            # åŒæ­¥çŠ¶æ€åˆ°é¢„å¤„ç†å™¨
            self.data_preprocessor.is_trained = self.is_trained
            self.data_preprocessor.training_features = self.training_features
        return result
    def get_model_status(self):
        """è·å–æ¨¡å‹å½“å‰çŠ¶æ€"""
        backup_count = 0
        backup_root = os.path.join(self.model_dir, "backup")
        if os.path.exists(backup_root):
            try:
                backup_count = len(os.listdir(backup_root))
            except Exception:
                backup_count = 0
        latest_eval = self.eval_history[-1] if self.eval_history else None
        return {
            "is_trained": self.is_trained,
            "total_samples": self.total_samples,
            "training_features_count": len(self.training_features) if self.training_features else 0,
            "target_features": self.data_preprocessor.target_features,
            "backup_count": backup_count,
            "latest_evaluation": latest_eval,
            "last_train_time": self.training_stats[-1]["timestamp"] if self.training_stats else None
        }


    def create_fixed_evaluation_set(self, data, size=50):
        """
        åˆ›å»ºå›ºå®šçš„è¯„ä¼°æ•°æ®é›†
        ç¡®ä¿ä¸åŒè®­ç»ƒé˜¶æ®µä½¿ç”¨ç›¸åŒçš„è¯„ä¼°åŸºå‡†

        :param data: è®­ç»ƒæ•°æ®
        :param size: è¯„ä¼°é›†å¤§å°
        :return: å›ºå®šè¯„ä¼°æ•°æ®é›†
        """
        try:
            if isinstance(data, list):
                df = pd.DataFrame(data)
            else:
                df = data.copy()
            # ç¡®ä¿æ•°æ®é‡è¶³å¤Ÿ
            if len(df) < size:
                logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}æ¡)ï¼Œæ— æ³•åˆ›å»º{size}æ¡çš„å›ºå®šè¯„ä¼°é›†")
                return df
            # æŒ‰å·¥ä½œé¢åˆ†å±‚é‡‡æ ·ï¼Œç¡®ä¿è¯„ä¼°é›†ä»£è¡¨æ€§
            fixed_eval_set = []
            if 'workface_id' in df.columns:
                workface_groups = df.groupby('workface_id')
                for workface_id, group in workface_groups:
                    group_size = max(1, int(size * len(group) / len(df)))
                    if len(group) >= group_size:
                        sampled = group.sample(n=group_size, random_state=42)
                        fixed_eval_set.append(sampled)
                if fixed_eval_set:
                    fixed_eval_df = pd.concat(fixed_eval_set, ignore_index=True)
                    # å¦‚æœæ€»æ•°è¶…è¿‡sizeï¼Œéšæœºé‡‡æ ·è°ƒæ•´
                    if len(fixed_eval_df) > size:
                        fixed_eval_df = fixed_eval_df.sample(n=size, random_state=42)
                else:
                    fixed_eval_df = df.sample(n=size, random_state=42)
            else:
                fixed_eval_df = df.sample(n=size, random_state=42)

            logger.info(f"åˆ›å»ºå›ºå®šè¯„ä¼°é›†: {len(fixed_eval_df)}æ¡æ•°æ®")
            return fixed_eval_df

        except Exception as e:
            logger.error(f"åˆ›å»ºå›ºå®šè¯„ä¼°é›†å¤±è´¥: {str(e)}")
            # å¤±è´¥æ—¶å›é€€åˆ°éšæœºé‡‡æ ·
            return df.sample(n=min(size, len(df)), random_state=42)

    def set_fixed_evaluation_set(self, data, size=50):
        """
        è®¾ç½®å›ºå®šè¯„ä¼°æ•°æ®é›†ä¾›åç»­ä½¿ç”¨
        """
        self.fixed_evaluation_set = self.create_fixed_evaluation_set(data, size)
        logger.info(f"å›ºå®šè¯„ä¼°é›†å·²è®¾ç½®: {len(self.fixed_evaluation_set)}æ¡æ•°æ®")
        return self.fixed_evaluation_set

    def retrain_from_db_full(self, workface_id=None, sample_limit=None, force_full_train=True):
        """
        å…¨é‡é‡æ–°è®­ç»ƒæ–¹æ³•ï¼ˆé˜²æ­¢æ¨¡å‹è¢«è¯¯åˆ é™¤ï¼Œå¼ºåˆ¶å…¨é‡è®­ç»ƒï¼‰

        :param workface_id: intï¼Œå¯é€‰ï¼Œç­›é€‰ç‰¹å®šå·¥ä½œé¢æ•°æ®
        :param sample_limit: intï¼Œå¯é€‰ï¼Œé™åˆ¶è®­ç»ƒæ ·æœ¬æ•°ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
        :param force_full_train: boolï¼Œæ˜¯å¦å¼ºåˆ¶å…¨é‡è®­ç»ƒï¼ˆé»˜è®¤Trueï¼‰
        :return: dictï¼Œè®­ç»ƒç»“æœ
        """
        with self.file_lock:
            self._print_header("å…¨é‡é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆä»æ•°æ®åº“æ¢å¤ï¼‰")
            retrain_start = datetime.now()
            try:
                # Step 1: ä»æ•°æ®åº“è¯»å–å†å²æ•°æ®ï¼ˆä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ï¼‰
                logger.info(f"ä»æ•°æ®åº“è¯»å–å†å²æ•°æ®ï¼šå·¥ä½œé¢å¯¹{workface_id}ï¼Œæ ·æœ¬é™åˆ¶{sample_limit}")
                df = self.model_manager.get_recent_data_from_db(self.db, limit=sample_limit)
                if 'measurement_date' in df.columns and pd.api.types.is_datetime64_any_dtype(df['measurement_date']):
                    df['measurement_date'] = df['measurement_date'].astype('int64') // 10 ** 9  # è½¬ä¸º Unix æ—¶é—´æˆ³
                    logger.info("æ•°æ®åº“è¯»å–çš„ measurement_date å·²è½¬æ¢ä¸º Unix æ—¶é—´æˆ³")
                if df.empty:
                    msg = "æœªä»æ•°æ®åº“è¯»å–åˆ°ä»»ä½•æ•°æ®ï¼Œæ— æ³•é‡æ–°è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": 0, "training_performed": False}
                    }
                # Step 2: ç­›é€‰ç‰¹å®šå·¥ä½œé¢æ•°æ®
                if workface_id is not None and 'workface_id' in df.columns:
                    original_count = len(df)
                    df = df[df["workface_id"] == workface_id].reset_index(drop=True)
                    if df.empty:
                        msg = f"å·¥ä½œé¢ID={workface_id} æ— æ•°æ®"
                        logger.warning(msg)
                        return {"status": "warning", "message": msg}
                    logger.info(f"ç­›é€‰å·¥ä½œé¢ID={workface_id}ï¼Œæ ·æœ¬æ•°ï¼š{original_count} â†’ {len(df)}")
                # Step 3: æ•°æ®é¢„å¤„ç†ï¼ˆé‡æ–°è®¡ç®—æ–­å±‚å½±å“ç³»æ•°ï¼‰
                logger.info("å…¨é‡é‡æ–°è®­ç»ƒï¼šè‡ªåŠ¨è®¡ç®—æ–­å±‚å½±å“ç³»æ•°")
                try:
                    df = self.calculate_fault_influence_strength(df)
                except Exception as e:
                    logger.error(f"è®¡ç®—æ–­å±‚å½±å“ç³»æ•°å¤±è´¥ï¼š{str(e)}ï¼Œä½¿ç”¨ç°æœ‰å€¼")
                    # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œä½¿ç”¨ç°æœ‰å€¼
                # Step 4: æ•°æ®é¢„å¤„ç†ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰
                try:
                    df_processed, training_features = self.data_preprocessor.preprocess_data(
                        df, is_training=True, fault_calculator=self.fault_calculator, db_utils=self.db
                    )
                except Exception as e:
                    logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
                    raise ValueError(f"æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
                # Step 5: æ£€æŸ¥æœ€å°æ ·æœ¬æ•°
                if len(df_processed) < self.min_train_samples:
                    msg = f"æ ·æœ¬æ•° {len(df_processed)} < æœ€å°è®­ç»ƒæ ·æœ¬æ•° {self.min_train_samples}ï¼Œæ— æ³•é‡æ–°è®­ç»ƒ"
                    logger.warning(msg)
                    self._print_result(msg)
                    return {
                        "status": "warning",
                        "message": msg,
                        "training_stats": {"processed_samples": len(df_processed), "training_performed": False}
                    }
                # Step 6: å¼ºåˆ¶é…ç½®ä¸ºå…¨é‡è®­ç»ƒæ¨¡å¼
                logger.info("å¼ºåˆ¶ä½¿ç”¨å…¨é‡è®­ç»ƒé…ç½®")
                # åˆ‡æ¢åˆ°å…¨é‡è®­ç»ƒé…ç½®ï¼ˆphase1ï¼‰
                config_before = self.current_config
                if self.current_config != "config_phase1.ini":
                    logger.info(f"åˆ‡æ¢åˆ°å…¨é‡è®­ç»ƒé…ç½®ï¼š{config_before} â†’ config_phase1.ini")
                    self.reload_config("config_phase1.ini", reload_database=False)
                # Step 7: æ„å»ºè®­ç»ƒé›†
                X = df_processed[training_features]
                y = df_processed[self.data_preprocessor.target_features].values
                fitted_feature_order = X.columns.tolist()
                # Step 8: ç‰¹å¾é¢„å¤„ç†
                preprocessor, X_proc, _ = self.model_trainer.create_preprocessor(
                    X, self.data_preprocessor.base_categorical
                )
                # Step 9: æ‰§è¡Œå…¨é‡è®­ç»ƒï¼ˆå¼ºåˆ¶ä½¿ç”¨å…¨é‡è®­ç»ƒé€»è¾‘ï¼‰
                logger.info(
                    f"å¼€å§‹å…¨é‡è®­ç»ƒï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼Œç›®æ ‡æ•°ï¼š{len(self.data_preprocessor.target_features)}")
                models = self.model_trainer._full_train(X_proc, y, self.data_preprocessor.target_features)
                # Step 10: æ›´æ–°æ¨¡å‹çŠ¶æ€
                self.models = models
                self.preprocessor = preprocessor
                self.training_features = training_features
                self._fitted_feature_order = fitted_feature_order
                self.is_trained = True
                self.data_preprocessor.is_trained = True
                self.data_preprocessor.training_features = training_features

                # Step 11: ä¿å­˜æ¨¡å‹ï¼ˆä¸è§¦å‘å¤‡ä»½ï¼Œå› ä¸ºæ˜¯æ¢å¤è®­ç»ƒï¼‰
                logger.info("ä¿å­˜é‡æ–°è®­ç»ƒçš„æ¨¡å‹")
                self.model_manager.save_model(self.models, self.preprocessor, self.training_features,
                                              self.data_preprocessor.target_features)
                # Step 12: æ¨¡å‹è¯„ä¼°
                eval_result = None
                if len(df_processed) > 5:  # é¿å…å°æ•°æ®è¯„ä¼°ä¸å‡†ç¡®
                    try:
                        eval_result = self.evaluate_model(eval_size=min(50, len(df_processed)), eval_df=df_processed)
                        logger.info(
                            f"é‡æ–°è®­ç»ƒåè¯„ä¼°ç»“æœï¼šçŠ¶æ€={eval_result.get('status')}, RMSE={eval_result.get('avg_rmse')}")
                    except Exception as e:
                        logger.warning(f"é‡æ–°è®­ç»ƒåè¯„ä¼°å¤±è´¥ï¼š{str(e)}")
                # Step 13: æ¢å¤åŸé…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if config_before != "config_phase1.ini":
                    logger.info(f"æ¢å¤åŸé…ç½®ï¼šconfig_phase1.ini â†’ {config_before}")
                    self.reload_config(config_before, reload_database=False)
                # Step 14: è®¡ç®—è®­ç»ƒè€—æ—¶
                train_duration = (datetime.now() - retrain_start).total_seconds()
                # Step 15: è®°å½•ç›‘æ§
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="full_retrain",  # ç‰¹æ®Šæ ‡è®°ä¸ºå…¨é‡é‡æ–°è®­ç»ƒ
                    sample_count=len(df_processed),
                    duration=train_duration,
                    rmse=eval_result.get("avg_rmse") if eval_result else None
                )
                # Step 16: è®°å½•è®­ç»ƒå†å²
                training_record = {
                    "sample_count": len(df_processed),
                    "total_samples": self.total_samples,  # æ³¨æ„ï¼šä¸æ›´æ–°æ€»æ ·æœ¬æ•°
                    "train_mode": "full_retrain",
                    "status": "success",
                    "message": f"å…¨é‡é‡æ–°è®­ç»ƒå®Œæˆï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼ŒRMSEï¼š{eval_result.get('avg_rmse') if eval_result else 'æœªè¯„ä¼°'}",
                    "duration": train_duration,
                    "train_time": datetime.now()
                }
                record_id = self.db.insert_training_record(training_record)
                # Step 17: æ„å»ºè¿”å›ç»“æœ
                training_result = {
                    "status": "success",
                    "message": f"å…¨é‡é‡æ–°è®­ç»ƒå®Œæˆï¼ˆæ ·æœ¬æ•°ï¼š{len(df_processed)}ï¼‰",
                    "training_stats": {
                        "processed_samples": len(df_processed),
                        "training_mode": "full_retrain",
                        "evaluation_rmse": eval_result.get("avg_rmse") if eval_result else None,
                        "training_duration": round(train_duration, 2),
                        "record_id": record_id,
                        "workface_filtered": workface_id is not None,
                        "sample_limit_applied": sample_limit is not None
                    },
                    "evaluation_details": eval_result if eval_result and eval_result.get(
                        "status") == "success" else None
                }
                # è¾“å‡ºè®­ç»ƒè¯Šæ–­ä¿¡æ¯
                if training_result.get("status") == "success":
                    self._print_training_diagnosis()
                logger.info(f"å…¨é‡é‡æ–°è®­ç»ƒæˆåŠŸå®Œæˆï¼Œè€—æ—¶ï¼š{train_duration:.2f}ç§’ï¼Œæ ·æœ¬æ•°ï¼š{len(df_processed)}")
                return training_result
            except Exception as e:
                # è®­ç»ƒå¤±è´¥å¤„ç†
                train_duration = (datetime.now() - retrain_start).total_seconds()
                logger.error(f"å…¨é‡é‡æ–°è®­ç»ƒå¤±è´¥ï¼š{str(e)}", exc_info=True)

                # è®°å½•ç›‘æ§
                from performance_monitor import global_monitor
                global_monitor.record_training_session(
                    train_mode="full_retrain_failed",
                    sample_count=len(df) if 'df' in locals() else 0,
                    duration=train_duration,
                    rmse=None
                )
                return {
                    "status": "error",
                    "message": str(e),
                    "training_stats": {
                        "processed_samples": len(df) if 'df' in locals() else 0,
                        "training_duration": round(train_duration, 2),
                        "training_performed": False
                    }
                }